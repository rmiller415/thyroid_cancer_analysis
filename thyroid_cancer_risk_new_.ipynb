{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eea998-fdd7-4a22-969c-ea0deac6f366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import copy\n",
    "import joblib\n",
    "import json\n",
    "import sklearn\n",
    "import imblearn\n",
    "import matplotlib\n",
    "import seaborn\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335382c0-0bc1-42ea-81d4-e45906da7859",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"pandas=={pandas.__version__}\")\n",
    "print(f\"joblib=={joblib.__version__}\")\n",
    "print(f\"json=={json.__version__}\")\n",
    "print(f\"scikit-learn=={sklearn.__version__}\")\n",
    "print(f\"imbalanced-learn=={imblearn.__version__}\")\n",
    "print(f\"matplotlib=={matplotlib.__version__}\")\n",
    "print(f\"seaborn=={seaborn.__version__}\")\n",
    "print(f\"numpy=={numpy.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10237d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTETomek\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "#Define global vars\n",
    "fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "model_results = {}\n",
    "df = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b53d8",
   "metadata": {},
   "source": [
    "# Data Processor:\n",
    "<ol type=\"1\">\n",
    "<li> Take in data, params, and drop_list. Check input data types and raise errors if necessary.\n",
    "<li> Transform the different data types in the data frame (one-hot encoding, ordinal encoding, etc.)\n",
    "<li> Perform data engineering tasks (e.g., dividing the TSH_Levels/T4_Levels or Nodule_Size/T3_Levels).\n",
    "<li> Drop any useless features (id numbers) and any transformed features (e.g. drop TSH_Levels and T4_Levels because of the feature engineering.\n",
    "<li> Return a dataframe with the cleaned data set.\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b5576f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PACKAGE LIST\n",
    "#pandas\n",
    "#logging\n",
    "#sklearn.preprocessing OneHotEncoder\n",
    "#imblearn.combine SMOTETomek\n",
    "class DataProcessor:\n",
    "    def __init__(self,data,params,logger):\n",
    "        self.logger = logger\n",
    "        self.logger.info('Initlizizing DataProcessor class')\n",
    "        \n",
    "        self.data = data\n",
    "        self.params = params\n",
    "        self.logger = logger\n",
    "\n",
    "        \n",
    "    def feat_ratios(self,top,bottom):\n",
    "        self.logger.debug('Before ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        '''Creates a new features by dividing two numerical features.\n",
    "\n",
    "        Inputs: top (string) - name of feature in dataset to be in the numerator of the ratio.\n",
    "                bottom (string) - name of feature in dataset to be in the denominator of the ratio.\n",
    "\n",
    "        Outputs: None - Appends new feature to the dataset, self.data.\n",
    "        \n",
    "        '''\n",
    "        #Divide top/bottom features\n",
    "        new_feat = top+':'+bottom\n",
    "        self.data[new_feat] = self.data[top]/self.data[bottom]\n",
    "        self.logger.debug('After ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_binaries(self,binary_feats,binary_map):\n",
    "        '''Encodes binary feats in a data set using the binary map dictionary. Entries in each feature\n",
    "            must be keys in the dictionary and will be replaced by the corresponding value in the dictionary.\n",
    "        \n",
    "        Inputs:\n",
    "            binary_feats (list of strings) - list containing strings with binary features \n",
    "            from the data set to be encoded.\n",
    "            \n",
    "            binary_maps (dictionary) - dictionary that has keys (string) corresponding to \n",
    "            entries in a binary feature. The values (int) of the dictionary will replace \n",
    "            the corresponding keys.\n",
    "        \n",
    "        Outputs:\n",
    "            None - Replaces the feature with a binary encoded feature in the dataset (self.data).\n",
    "        '''\n",
    "        self.logger.debug('Before binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        self.data[binary_feats] = self.data[binary_feats].map(lambda x: binary_map[x])\n",
    "        self.logger.debug('After binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "    def encode_catnoms(self, catnom_feats, encode_type='one_hot'):\n",
    "        '''\n",
    "        Performs encoding on categorical nominal features. Currently only supports one hot encoding.\n",
    "        \n",
    "        Inputs:\n",
    "            catnom_feats (list of strings) - Each string in the list is the name of a categorical \n",
    "            nominal feature to be encoded.\n",
    "            \n",
    "            encode_type (str) - Type of encoding to be performed on categorical nominal features.\n",
    "                Currently only one hot encoding is implimented.\n",
    "                \n",
    "        Outputs:\n",
    "            None - appends the encoded features to the data set (self.data) and drops the unencoded\n",
    "            features.\n",
    "        \n",
    "        '''\n",
    "        self.logger.debug('Before categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        if encode_type == 'one_hot':\n",
    "            #Initialize encoder and fit transform\n",
    "            ohe_encoder = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "            ohe_encoded = ohe_encoder.fit_transform(self.data[catnom_feats])\n",
    "            col_names = ohe_encoder.get_feature_names_out(catnom_feats)\n",
    "            encoded_feats = pd.DataFrame(ohe_encoded,columns=col_names)\n",
    "\n",
    "            #Reset indices to ensure alignment of the dataframe\n",
    "            #then concatenate data with encoded feats\n",
    "            self.data.reset_index(drop=True,inplace=True)\n",
    "            encoded_feats.reset_index(drop=True,inplace=True)\n",
    "            self.data = pd.concat([self.data,encoded_feats],axis=1)\n",
    "            \n",
    "            #Drop unencoded features to prevent issues with resampling and model fitting.\n",
    "            self.data.drop(columns=catnom_feats,axis=1,inplace=True)\n",
    "        self.logger.debug('After categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_catords(self,catord_feats,catord_map):\n",
    "        '''\n",
    "        Encodes categorical ordinal features using a mapping dictionary. Replaces the unencoded features\n",
    "        with encoded features.\n",
    "        \n",
    "        Inputs: \n",
    "            catord_feats (list of strings) - Each string in the list must be a feature name in\n",
    "                the dataset.\n",
    "                \n",
    "            catord_map (dict) - Dictionary of features containing keys (str) that are in the unencoded\n",
    "                feature and corresponding values (int) that will be replacing the unencoded entries.\n",
    "                \n",
    "        Outputs:\n",
    "            None - Replaces the unencoded feature in the dataset (self.data)\n",
    "        '''\n",
    "        self.logger.debug('Before categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        #Apply encoding\n",
    "        self.data[catord_feats] = self.data[catord_feats].map(lambda x: catord_map[x])\n",
    "        self.logger.debug('After categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def smote_tomek(self,target_name):\n",
    "        '''\n",
    "        Performs SMOTETomek resampling to prevent model bias towards a majority feature.\n",
    "        \n",
    "        This function MUST be used AFTER encoding all features. Non-numeric features will raise\n",
    "        an error.\n",
    "        \n",
    "        Inputs:\n",
    "            target_name (str) - Name of the feature to be predicted (truth or target).\n",
    "            \n",
    "        Outputs:\n",
    "            None - Resampled replaces the old data.\n",
    "        '''\n",
    "        self.logger.debug('Before SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')\n",
    "        #Split data into features and target\n",
    "        X = self.data\n",
    "        y = self.data.pop(target_name)\n",
    "        \n",
    "        #Initialize and fit data\n",
    "        smote_tomek = SMOTETomek()\n",
    "        X_resampled, y_resampled = smote_tomek.fit_resample(X,y)\n",
    "        \n",
    "        #Concatenate data and replaced ata set.\n",
    "        self.data = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "    \n",
    "        self.logger.debug('After SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug('After SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c4b51a",
   "metadata": {},
   "source": [
    "# Pipeline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64da3ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PACKAGE LIST\n",
    "#logging\n",
    "#pandas\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),  # writes to file\n",
    "        logging.StreamHandler()               # prints to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EncodingPipeLine:\n",
    "    def __init__(self,raw_data,logger,run=True,ratios=None):\n",
    "        '''\n",
    "        Initializes PipeLine class that will pass data to DataProcessor class. After a successful run\n",
    "        all data should be encoded and the data set should be resampled (if necessary).\n",
    "        \n",
    "        Inputs: \n",
    "            raw_data (pd.DataFrame) - Data set that will be encoded and resampled. Stored to retain\n",
    "                the dataset for future use and testing.\n",
    "                \n",
    "            run (bool) - If true, the pipeline will pass the data through the encoding class.\n",
    "            \n",
    "            ratios (list/tuple of list/tuples of strings) - The features to be turned into a ratio \n",
    "                are placed into a list/tuple where position 0 is the numerator and position 1 is \n",
    "                the denominator. If multiple ratios need to be taken then they can be passed \n",
    "                as a list of lists.\n",
    "                \n",
    "                [(feat1,feat2),(feat3,feat4)] will give the rations feat1/feat2 and feat3/feat4.\n",
    "    \n",
    "        '''\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        logger.info('Initializing PipeLine class')\n",
    "        logger.debug('Raw Data Shape: {self.raw_data.shape}')\n",
    "        logger.debug('Raw Data Features: {self.raw_data.columns}')\n",
    "        \n",
    "        self.raw_data = raw_data\n",
    "        self.ratios = ratios\n",
    "        self.parameter_loader()\n",
    "        \n",
    "        if self.ratios == 'all':\n",
    "            self.ratios = [v for k,v in self.params['feat_ratio_names'].items()]\n",
    "            \n",
    "        if run == True:\n",
    "            self.run_pipeline()\n",
    "            \n",
    "    def parameter_loader(self):\n",
    "        self.logger.info('Loading parameter dictionary.')\n",
    "        '''\n",
    "        Generates parameter dictionary. This will be replaced later with a json or yaml loading function.\n",
    "        \n",
    "        '''\n",
    "        self.params = {\n",
    "            'feat_categories':{\n",
    "                'numerical_continuous':['TSH_Level','T3_Level','T4_Level','Nodule_Size',],\n",
    "                'ordinal':['Age'],\n",
    "                'binary':['Gender','Family_History','Radiation_Exposure','Iodine_Deficiency',\n",
    "                    'Smoking','Obesity','Diabetes','Diagnosis',],\n",
    "                'categorical_nominal':['Country','Ethnicity',],\n",
    "                'categorical_ordinal':['Thyroid_Cancer_Risk',],\n",
    "            },\n",
    "            'encoding_utils':{\n",
    "                'binary':{'Yes':1.0,'No':0.0,'Male':1.0,'Female':0.0,'Benign':0.0,'Malignant':1.0},\n",
    "                'categorical_ordinal':{'Low':0.0,'Medium':1.0,'High':2.0},\n",
    "            },\n",
    "            'train_test':{\n",
    "                'test_size':0.2,\n",
    "            },\n",
    "            'feat_ratio_names':{\n",
    "                'ratio_1':['TSH_Level','T3_Level'],\n",
    "                'ratio_2':['Nodule_Size','T4_Level'],\n",
    "                'ratio_3':['TSH_Level','T4_Level'],\n",
    "                'ratio_4':['Nodule_Size','T3_Level']\n",
    "            },\n",
    "            'resample':'SMOTETomek',\n",
    "            'target_name':'Diagnosis',\n",
    "            \n",
    "        }\n",
    "        self.logger.info('Parameter file loaded successfully.')\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.logger.info('Initializing DataProcessor class.')\n",
    "        #Initialize data processing class\n",
    "        data_processor = DataProcessor(data=self.raw_data,logger=self.logger, params=self.params)\n",
    "        self.logger.info('DataProcessor class initialized successfully.')\n",
    "        \n",
    "        \n",
    "        #Make ratio features\n",
    "        if self.ratios:\n",
    "            self.logger.info('Creating ratios of features.')\n",
    "            for ratio in self.ratios:\n",
    "                data_processor.feat_ratios(ratio[0],ratio[1])\n",
    "            self.logger.info('Ratio features created successfully.')\n",
    "        \n",
    "        #Encode binary features\n",
    "        self.logger.info('Encoding binary features.')\n",
    "        data_processor.encode_binaries(\n",
    "            binary_feats=self.params['feat_categories']['binary'],\n",
    "            binary_map=self.params['encoding_utils']['binary'],\n",
    "        )\n",
    "        self.logger.info('Binary features encoded successfully.')\n",
    "        \n",
    "        #Encode categorical nominal features\n",
    "        self.logger.info('Begin encoding categorical nominal features.')\n",
    "        data_processor.encode_catnoms(\n",
    "            catnom_feats=self.params['feat_categories']['categorical_nominal'],\n",
    "        )\n",
    "        self.logger.info('Categorical nominal features encoded successfully.')\n",
    "        \n",
    "        self.logger.info('Begin encoding catagorical ordinal features.')\n",
    "        data_processor.encode_catords(\n",
    "            catord_feats=self.params['feat_categories']['categorical_ordinal'],\n",
    "            catord_map=self.params['encoding_utils']['categorical_ordinal'],\n",
    "        )\n",
    "        self.logger.info('Categorical ordinal features encoded successfully.')\n",
    "        \n",
    "        \n",
    "        if self.params['resample'] == 'SMOTETomek':\n",
    "            self.logger.info('Begin resampling of data.')\n",
    "            data_processor.smote_tomek(target_name=self.params['target_name'])\n",
    "            self.logger.info('Resampling of data completed successfully.')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        self.data = data_processor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aa4e5b",
   "metadata": {},
   "source": [
    "# Model Saver:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580a48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Packages:\n",
    "#pandas\n",
    "#joblib\n",
    "#json\n",
    "#pathlib\n",
    "class ModelSaver:\n",
    "    def __init__(self,algorithm,X_valid,y_valid,output_dir,iteration_start=0,notes=None,save_params=False,params=None):\n",
    "        self.algorithm = algorithm\n",
    "        self.notes = notes\n",
    "        self.output_dir = output_dir\n",
    "        self.save_params = save_params\n",
    "        self.params = params\n",
    "        self.iteration = iteration_start\n",
    "        self.model_save = {}\n",
    "        \n",
    "        if self.params != None:\n",
    "            self.model_save['params'] = params\n",
    "\n",
    "    def record_state(self, model, X_test, X_train, y_test, y_train, model_preds,model_scores,drop_list,params=None,model_notes=None):\n",
    "        current_model = {\n",
    "            'model':model,\n",
    "            'X_test':X_test,\n",
    "            'X_train':X_train,\n",
    "            'y_test':y_test,\n",
    "            'y_train':y_train,\n",
    "            'model_preds':model_preds,\n",
    "            'model_notes':model_notes,\n",
    "            'model_scores':model_scores,\n",
    "        }\n",
    "        \n",
    "        if self.save_params == True:\n",
    "            current_model['params'] = params\n",
    "            \n",
    "        \n",
    "        self.model_save[self.algorithm+'_'+str(self.iteration)] = current_model\n",
    "        self.iteration += 1\n",
    "            \n",
    "            \n",
    "    def save_state(self,output_fname,output_dir):\n",
    "            \n",
    "        dir_path = Path(output_dir)\n",
    "        fpath = dir_path/output_fname\n",
    "        joblib.dump(self.model_save, fpath)\n",
    "    \n",
    "    def update_state(self, algorithm, iteration):\n",
    "        self.algorithm = algorithm\n",
    "        self.iteration = iteration\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6a95b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 14:01:40,804 - INFO - Initializing PipeLine class\n",
      "2025-03-29 14:01:40,807 - INFO - Loading parameter dictionary.\n",
      "2025-03-29 14:01:40,808 - INFO - Parameter file loaded successfully.\n",
      "2025-03-29 14:01:40,809 - INFO - Initializing DataProcessor class.\n",
      "2025-03-29 14:01:40,809 - INFO - Initlizizing DataProcessor class\n",
      "2025-03-29 14:01:40,810 - INFO - DataProcessor class initialized successfully.\n",
      "2025-03-29 14:01:40,811 - INFO - Creating ratios of features.\n",
      "2025-03-29 14:01:40,822 - INFO - Ratio features created successfully.\n",
      "2025-03-29 14:01:40,823 - INFO - Encoding binary features.\n",
      "2025-03-29 14:01:41,185 - INFO - Binary features encoded successfully.\n",
      "2025-03-29 14:01:41,186 - INFO - Begin encoding categorical nominal features.\n",
      "2025-03-29 14:01:41,465 - INFO - Categorical nominal features encoded successfully.\n",
      "2025-03-29 14:01:41,466 - INFO - Begin encoding catagorical ordinal features.\n",
      "2025-03-29 14:01:41,525 - INFO - Categorical ordinal features encoded successfully.\n",
      "2025-03-29 14:01:41,526 - INFO - Begin resampling of data.\n",
      "2025-03-29 14:03:54,163 - INFO - Resampling of data completed successfully.\n"
     ]
    }
   ],
   "source": [
    "fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "X_raw = pd.read_csv(fpath)\n",
    "y_raw = X_raw.pop('Diagnosis')\n",
    "\n",
    "X, X_valid, y, y_valid = train_test_split(X_raw,y_raw,test_size=0.2,stratify=y_raw)\n",
    "\n",
    "data = pd.concat([X,y],axis=1)\n",
    "\n",
    "pipeline = EncodingPipeLine(raw_data=deepcopy(data),logger=logger,ratios='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec7a77d-d015-4fb8-aa59-2986478e68fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "data_save = {\n",
    "    'X_valid':X_valid,\n",
    "    'y_valid':y_valid,\n",
    "    'data':pipeline.data,\n",
    "}\n",
    "\n",
    "with open(\"resampled_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_save, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b11386b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_select(data, drop_list,target,ohe_feats=None,test_size=None):\n",
    "    data.drop(columns=drop_list,inplace=True,axis=1)\n",
    "    if ohe_feats:\n",
    "        for feat in ohe_feats:\n",
    "            data.drop(columns=data.filter(like=feat+'_').columns, inplace=True, axis=1)\n",
    "        \n",
    "    X = data\n",
    "    y = data.pop(target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)\n",
    "\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d31e422",
   "metadata": {},
   "source": [
    "# Model 1 - Nodule_Size:T3_Level and TSH_Level:T4_Level\n",
    "\n",
    "## Does Not Include: Gender, Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a26aaa62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30193\n",
      "         1.0       0.93      0.82      0.87     30320\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_1 = [\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Gender'\n",
    "]\n",
    "\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_1,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_1 = RandomForestClassifier()\n",
    "rf_model_1.fit(X_train_1, y_train_1)\n",
    "\n",
    "preds_1 = rf_model_1.predict(X_test_1)\n",
    "report_1 = classification_report(y_test_1,preds_1)\n",
    "\n",
    "print(report_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506bd51",
   "metadata": {},
   "source": [
    "# Model 2 - Nodule_Size:T4_Level and TSH_Level:T3_Level\n",
    "\n",
    "## Does Not Include: Gender, Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bec75ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30082\n",
      "         1.0       0.93      0.82      0.87     30431\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_2 = [\n",
    "    'T4_Level',\n",
    "    'Gender',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "]\n",
    "\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_2,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_2 = RandomForestClassifier()\n",
    "rf_model_2.fit(X_train_2, y_train_2)\n",
    "\n",
    "preds_2 = rf_model_2.predict(X_test_2)\n",
    "report_2 = classification_report(y_test_2,preds_2)\n",
    "\n",
    "\n",
    "print(report_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b1301f",
   "metadata": {},
   "source": [
    "# Model 3 - No Ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5840187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89     30302\n",
      "         1.0       0.94      0.83      0.88     30211\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_3 = [\n",
    "    'Gender',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "]\n",
    "\n",
    "X_train_3, X_test_3, y_train_3, y_test_3 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_3,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "rf_model_3 = RandomForestClassifier()\n",
    "rf_model_3.fit(X_train_3, y_train_3)\n",
    "\n",
    "preds_3 = rf_model_3.predict(X_test_3)\n",
    "report_3 = classification_report(y_test_3,preds_3)\n",
    "model_results['model_3'] = report_3\n",
    "\n",
    "print(report_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2b8d17",
   "metadata": {},
   "source": [
    "# Model 4 - Nodule_Size:T3_Level and TSH_Level:T4_Level\n",
    "\n",
    "## Includes: Ethnicity\n",
    "## Does Note Include: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b111f4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30122\n",
      "         1.0       0.93      0.82      0.87     30391\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_4 = [\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Gender'\n",
    "]\n",
    "\n",
    "X_train_4, X_test_4, y_train_4, y_test_4 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_4,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_4 = RandomForestClassifier()\n",
    "rf_model_4.fit(X_train_4, y_train_4)\n",
    "\n",
    "preds_4 = rf_model_4.predict(X_test_4)\n",
    "report_4 = classification_report(y_test_4,preds_4)\n",
    "model_results['model_4'] = report_4\n",
    "\n",
    "print(report_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0ec386",
   "metadata": {},
   "source": [
    "# Model 5 - Nodule_Size:T4_Level and TSH_Level:T3_Level\n",
    "\n",
    "## Includes: Ethnicity\n",
    "## Does Note Include: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2c5e75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30227\n",
      "         1.0       0.93      0.82      0.87     30286\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_5 = [\n",
    "    'T4_Level',\n",
    "    'Gender',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "]\n",
    "\n",
    "X_train_5, X_test_5, y_train_5, y_test_5 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_5,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_5 = RandomForestClassifier()\n",
    "rf_model_5.fit(X_train_5, y_train_5)\n",
    "\n",
    "preds_5 = rf_model_5.predict(X_test_5)\n",
    "report_5 = classification_report(y_test_5,preds_5)\n",
    "\n",
    "\n",
    "print(report_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b6d274",
   "metadata": {},
   "source": [
    "# Model 6 - No Ratios\n",
    "\n",
    "## Includes: Ethnicity\n",
    "## Does Note Include: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc8110b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89     30112\n",
      "         1.0       0.94      0.83      0.88     30401\n",
      "\n",
      "    accuracy                           0.89     60513\n",
      "   macro avg       0.89      0.89      0.89     60513\n",
      "weighted avg       0.89      0.89      0.89     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_6 = [\n",
    "    'Gender',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "]\n",
    "\n",
    "X_train_6, X_test_6, y_train_6, y_test_6 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_6,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "rf_model_6 = RandomForestClassifier()\n",
    "rf_model_6.fit(X_train_6, y_train_6)\n",
    "\n",
    "preds_6 = rf_model_6.predict(X_test_6)\n",
    "report_6 = classification_report(y_test_6,preds_6)\n",
    "\n",
    "print(report_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd835c6",
   "metadata": {},
   "source": [
    "# Model 7 - Nodule_Size:T3_Level and TSH_Level:T4_Level\n",
    "\n",
    "## Includes: Gender\n",
    "## Does Note Include: Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bfe75da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30430\n",
      "         1.0       0.93      0.82      0.87     30083\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_7 = [\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "]\n",
    "\n",
    "X_train_7, X_test_7, y_train_7, y_test_7 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_7,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_7 = RandomForestClassifier()\n",
    "rf_model_7.fit(X_train_7, y_train_7)\n",
    "\n",
    "preds_7 = rf_model_7.predict(X_test_7)\n",
    "report_7 = classification_report(y_test_7,preds_7)\n",
    "\n",
    "print(report_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90059d4c",
   "metadata": {},
   "source": [
    "# Model 8 - Nodule_Size:T4_Level and TSH_Level:T3_Level\n",
    "\n",
    "## Includes: Gender\n",
    "## Does Note Include: Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9a4df9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30071\n",
      "         1.0       0.94      0.82      0.87     30442\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_8 = [\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "]\n",
    "\n",
    "X_train_8, X_test_8, y_train_8, y_test_8 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_8,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_8 = RandomForestClassifier()\n",
    "rf_model_8.fit(X_train_8, y_train_8)\n",
    "\n",
    "preds_8 = rf_model_8.predict(X_test_8)\n",
    "report_8 = classification_report(y_test_8,preds_8)\n",
    "\n",
    "\n",
    "print(report_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b449c4ce",
   "metadata": {},
   "source": [
    "# Model 9 - No Ratios\n",
    "\n",
    "## Includes: Gender\n",
    "## Does Note Include: Ethnicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "03d41353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30109\n",
      "         1.0       0.94      0.83      0.88     30404\n",
      "\n",
      "    accuracy                           0.89     60513\n",
      "   macro avg       0.89      0.89      0.89     60513\n",
      "weighted avg       0.89      0.89      0.89     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_9 = [\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "]\n",
    "\n",
    "X_train_9, X_test_9, y_train_9, y_test_9 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_9,\n",
    "    ohe_feats=['Ethnicity'],\n",
    "    target='Diagnosis'\n",
    ")\n",
    "rf_model_9 = RandomForestClassifier()\n",
    "rf_model_9.fit(X_train_9, y_train_9)\n",
    "\n",
    "preds_9 = rf_model_9.predict(X_test_9)\n",
    "report_9 = classification_report(y_test_9,preds_9)\n",
    "model_results['model_9'] = report_9\n",
    "\n",
    "print(report_9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcdbf39",
   "metadata": {},
   "source": [
    "# Model 10 - Nodule_Size:T3_Level and TSH_Level:T4_Level\n",
    "\n",
    "## Includes: Gender, Ethnicity\n",
    "## Does Note Include: NONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "480c969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30284\n",
      "         1.0       0.93      0.82      0.87     30229\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_10 = [\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "]\n",
    "\n",
    "X_train_10, X_test_10, y_train_10, y_test_10 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_10,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_10 = RandomForestClassifier()\n",
    "rf_model_10.fit(X_train_10, y_train_10)\n",
    "\n",
    "preds_10 = rf_model_10.predict(X_test_10)\n",
    "report_10 = classification_report(y_test_10,preds_10)\n",
    "\n",
    "print(report_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b6831",
   "metadata": {},
   "source": [
    "# Model 11 - Nodule_Size:T4_Level and TSH_Level:T3_Level\n",
    "\n",
    "## Includes: Gender, Ethnicity\n",
    "## Does Note Include: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76139140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.94      0.89     30052\n",
      "         1.0       0.94      0.82      0.87     30461\n",
      "\n",
      "    accuracy                           0.88     60513\n",
      "   macro avg       0.89      0.88      0.88     60513\n",
      "weighted avg       0.89      0.88      0.88     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_11 = [\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "]\n",
    "\n",
    "X_train_11, X_test_11, y_train_11, y_test_11 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_11,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "\n",
    "rf_model_11 = RandomForestClassifier()\n",
    "rf_model_11.fit(X_train_11, y_train_11)\n",
    "\n",
    "preds_11 = rf_model_11.predict(X_test_11)\n",
    "report_11 = classification_report(y_test_11,preds_11)\n",
    "\n",
    "\n",
    "print(report_11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da64c47",
   "metadata": {},
   "source": [
    "# Model 12 - No Ratios\n",
    "\n",
    "## Includes: Gender, Ethnicity\n",
    "## Does Note Include: None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "436fabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89     30082\n",
      "         1.0       0.93      0.83      0.88     30431\n",
      "\n",
      "    accuracy                           0.89     60513\n",
      "   macro avg       0.89      0.89      0.89     60513\n",
      "weighted avg       0.89      0.89      0.89     60513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_12 = [\n",
    "    'Patient_ID',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "]\n",
    "\n",
    "X_train_12, X_test_12, y_train_12, y_test_12 = model_data_select(\n",
    "    data=deepcopy(pipeline.data),\n",
    "    drop_list=drop_12,\n",
    "    ohe_feats=None,\n",
    "    target='Diagnosis'\n",
    ")\n",
    "rf_model_12 = RandomForestClassifier()\n",
    "rf_model_12.fit(X_train_12, y_train_12)\n",
    "\n",
    "preds_12 = rf_model_12.predict(X_test_12)\n",
    "report_12 = classification_report(y_test_12,preds_12)\n",
    "\n",
    "print(report_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15547c59-61a4-49f6-a42c-687056b542d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'model_1':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender'],\n",
    "        'model_notes':'Ratios are Nodule_Size:T3_Level and TSH_Level:T4_Level. Does not include: Gender, Ethnicity',\n",
    "    },\n",
    "    'model_2':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['T4_Level','Gender','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T4_Level and TSH_Level:T3_Level. Does not include: Gender, Ethnicity',\n",
    "    },\n",
    "    'model_3':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Gender','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level','Nodule_Size:T4_Level','TSH_Level:T3_Level',],\n",
    "        'model_notes':'No ratios. Does not include: Gender, Ethnicity',\n",
    "    },\n",
    "    'model_4':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T3_Level and TSH_Level:T4_Level. Does not include: Gender',\n",
    "    },\n",
    "    'model_5':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['T4_Level','Gender','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T4_Level and TSH_Level:T3_Level. Does not include: Gender',\n",
    "    },\n",
    "    'model_6':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Gender','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level','Nodule_Size:T4_Level','TSH_Level:T3_Level',],\n",
    "        'model_notes':'No ratios. Does not include: Gender',\n",
    "    },\n",
    "    'model_7':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T3_Level and TSH_Level:T4_Level. Does not include: Ethnicity',\n",
    "    },\n",
    "    'model_8':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T4_Level and TSH_Level:T3_Level. Does not include: Ethnicity',\n",
    "    },\n",
    "    'model_9':{\n",
    "        'ohe_feats':'Ethnicity',\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level','Nodule_Size:T4_Level','TSH_Level:T3_Level',],\n",
    "        'model_notes':'No ratios. Does not include: Ethnicity',\n",
    "    },\n",
    "    'model_10':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T3_Level and TSH_Level:T4_Level. Includes all feats.',\n",
    "    },\n",
    "    'model_11':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level',],\n",
    "        'model_notes':'Ratios are Nodule_Size:T4_Level and TSH_Level:T3_Level. Includes all feats.',\n",
    "    },\n",
    "    'model_12':{\n",
    "        'ohe_feats':None,\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Patient_ID','Nodule_Size:T3_Level','TSH_Level:T4_Level','Nodule_Size:T4_Level','TSH_Level:T3_Level',],\n",
    "        'model_notes':'No ratios. Includes all feats.',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f844d587-a317-465c-9fcf-75340cf1b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_iterator(data,X_valid,y_valid,params,model_dict,fname,dirname,target):\n",
    "    for i, (k,v) in enumerate(model_dict.items()):\n",
    "\n",
    "        #Initialize model saver class\n",
    "        if i == 0:\n",
    "            logging.info('Initializing ModelSaver class')\n",
    "        \n",
    "            model_saver = ModelSaver(\n",
    "            v['algorithm'],\n",
    "            X_valid,\n",
    "            y_valid,\n",
    "            output_dir='/Users/richardmiller/Downloads/',\n",
    "            iteration_start=i,\n",
    "            params=params,\n",
    "        )\n",
    "            algorithm_ = v['algorithm']\n",
    "            \n",
    "        #Check if model changed between iterations\n",
    "        if v['algorithm'] != algorithm_:\n",
    "            model_saver.update_state(v['algorithm'],i)\n",
    "\n",
    "            \n",
    "        logging.info('Training Model.')\n",
    "\n",
    "        if v['algorithm'] == 'RandomForestClassifier':\n",
    "            #Split data into train and test sets\n",
    "            X_train, X_test, y_train, y_test = model_data_select(\n",
    "                data=deepcopy(data),\n",
    "                drop_list=v['drop_list'],\n",
    "                ohe_feats=v['ohe_feats'],\n",
    "                target=target\n",
    "            )\n",
    "    \n",
    "            #Fit model\n",
    "            rf_model = RandomForestClassifier()\n",
    "            rf_model.fit(X_train, y_train)\n",
    "    \n",
    "            #Make predictions and evaluate with report metric\n",
    "            preds = rf_model.predict(X_test)\n",
    "            report = classification_report(y_test,preds)\n",
    "            logging.info('Model trained.')\n",
    "            if verbose == True:\n",
    "                print(report)\n",
    "    \n",
    "            logging.info('Saving state.')\n",
    "    \n",
    "            #Append current model data to all other data.\n",
    "            model_saver.record_save(\n",
    "            model=rf_model,\n",
    "            X_test=X_test,\n",
    "            X_train=X_train,\n",
    "            y_test=y_test,\n",
    "            y_train=y_train,\n",
    "            model_scores=report,\n",
    "            drop_list=v['drop_list'],\n",
    "            model_notes=v['model_notes'],\n",
    "        )\n",
    "            logging.info('State saved successfully')\n",
    "    \n",
    "            #Set the test variable\n",
    "            algorithm_ = v['algorithm']\n",
    "\n",
    "        if i == len(model_dict.keys()):\n",
    "            model_saver.save_state(output_fname=fname, output_dir=dirname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e5e1aa66-0de7-44c0-ac5e-3a767cca8c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-29 21:47:53,342 - INFO - Initializing ModelSaver class\n",
      "2025-03-29 21:47:53,344 - INFO - Training Model.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Nodule_Size:T4_Level', 'TSH_Level:T3_Level'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m thingy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthyroid_cancer_models.pkl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/richardmiller/Downloads/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDiagnosis\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[57], line 27\u001b[0m, in \u001b[0;36mmodel_iterator\u001b[0;34m(data, X_valid, y_valid, params, model_dict, fname, dirname, target)\u001b[0m\n\u001b[1;32m     23\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining Model.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malgorithm\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandomForestClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#Split data into train and test sets\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_data_select\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeepcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdrop_list\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mohe_feats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mohe_feats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#Fit model\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     rf_model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m, in \u001b[0;36mmodel_data_select\u001b[0;34m(data, drop_list, target, ohe_feats, test_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_data_select\u001b[39m(data, drop_list,target,ohe_feats\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ohe_feats:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m ohe_feats:\n",
      "File \u001b[0;32m~/anaconda3/envs/thyroid_cancer_venv/lib/python3.10/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/thyroid_cancer_venv/lib/python3.10/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/anaconda3/envs/thyroid_cancer_venv/lib/python3.10/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/thyroid_cancer_venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Nodule_Size:T4_Level', 'TSH_Level:T3_Level'] not found in axis\""
     ]
    }
   ],
   "source": [
    "thingy = model_iterator(data,X_valid,y_valid,pipeline.params,models,'thyroid_cancer_models.pkl','/Users/richardmiller/Downloads/','Diagnosis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead0c6f-c8ae-4fc6-ba9a-c4a1eb27197c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
