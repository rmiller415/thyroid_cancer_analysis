{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4df383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.combine import SMOTETomek\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "#Define global vars\n",
    "fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "model_results = {}\n",
    "df = pd.read_csv(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb66fa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),  # writes to file\n",
    "        logging.StreamHandler()               # prints to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f57b9",
   "metadata": {},
   "source": [
    "# Data Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea8d6328",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self,data,params,logger):\n",
    "        self.logger = logger\n",
    "        self.logger.info('Initlizizing DataProcessor class')\n",
    "        \n",
    "        self.data = data\n",
    "        self.params = params\n",
    "        self.logger = logger\n",
    "\n",
    "        \n",
    "    def feat_ratios(self,top,bottom):\n",
    "        self.logger.debug('Before ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        '''Creates a new features by dividing two numerical features.\n",
    "\n",
    "        Inputs: top (string) - name of feature in dataset to be in the numerator of the ratio.\n",
    "                bottom (string) - name of feature in dataset to be in the denominator of the ratio.\n",
    "\n",
    "        Outputs: None - Appends new feature to the dataset, self.data.\n",
    "        \n",
    "        '''\n",
    "        #Divide top/bottom features\n",
    "        new_feat = top+':'+bottom\n",
    "        self.data[new_feat] = self.data[top]/self.data[bottom]\n",
    "        self.logger.debug('After ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_binaries(self,binary_feats,binary_map):\n",
    "        '''Encodes binary feats in a data set using the binary map dictionary. Entries in each feature\n",
    "            must be keys in the dictionary and will be replaced by the corresponding value in the dictionary.\n",
    "        \n",
    "        Inputs:\n",
    "            binary_feats (list of strings) - list containing strings with binary features \n",
    "            from the data set to be encoded.\n",
    "            \n",
    "            binary_maps (dictionary) - dictionary that has keys (string) corresponding to \n",
    "            entries in a binary feature. The values (int) of the dictionary will replace \n",
    "            the corresponding keys.\n",
    "        \n",
    "        Outputs:\n",
    "            None - Replaces the feature with a binary encoded feature in the dataset (self.data).\n",
    "        '''\n",
    "        self.logger.debug('Before binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        self.data[binary_feats] = self.data[binary_feats].map(lambda x: binary_map[x])\n",
    "        self.logger.debug('After binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "    def encode_catnoms(self, catnom_feats, encode_type='one_hot'):\n",
    "        '''\n",
    "        Performs encoding on categorical nominal features. Currently only supports one hot encoding.\n",
    "        \n",
    "        Inputs:\n",
    "            catnom_feats (list of strings) - Each string in the list is the name of a categorical \n",
    "            nominal feature to be encoded.\n",
    "            \n",
    "            encode_type (str) - Type of encoding to be performed on categorical nominal features.\n",
    "                Currently only one hot encoding is implimented.\n",
    "                \n",
    "        Outputs:\n",
    "            None - appends the encoded features to the data set (self.data) and drops the unencoded\n",
    "            features.\n",
    "        \n",
    "        '''\n",
    "        self.logger.debug('Before categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        if encode_type == 'one_hot':\n",
    "            #Initialize encoder and fit transform\n",
    "            ohe_encoder = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "            ohe_encoded = ohe_encoder.fit_transform(self.data[catnom_feats])\n",
    "            col_names = ohe_encoder.get_feature_names_out(catnom_feats)\n",
    "            encoded_feats = pd.DataFrame(ohe_encoded,columns=col_names)\n",
    "\n",
    "            #Reset indices to ensure alignment of the dataframe\n",
    "            #then concatenate data with encoded feats\n",
    "            self.data.reset_index(drop=True,inplace=True)\n",
    "            encoded_feats.reset_index(drop=True,inplace=True)\n",
    "            self.data = pd.concat([self.data,encoded_feats],axis=1)\n",
    "            \n",
    "            #Drop unencoded features to prevent issues with resampling and model fitting.\n",
    "            self.data.drop(columns=catnom_feats,axis=1,inplace=True)\n",
    "        self.logger.debug('After categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_catords(self,catord_feats,catord_map):\n",
    "        '''\n",
    "        Encodes categorical ordinal features using a mapping dictionary. Replaces the unencoded features\n",
    "        with encoded features.\n",
    "        \n",
    "        Inputs: \n",
    "            catord_feats (list of strings) - Each string in the list must be a feature name in\n",
    "                the dataset.\n",
    "                \n",
    "            catord_map (dict) - Dictionary of features containing keys (str) that are in the unencoded\n",
    "                feature and corresponding values (int) that will be replacing the unencoded entries.\n",
    "                \n",
    "        Outputs:\n",
    "            None - Replaces the unencoded feature in the dataset (self.data)\n",
    "        '''\n",
    "        self.logger.debug('Before categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        #Apply encoding\n",
    "        self.data[catord_feats] = self.data[catord_feats].map(lambda x: catord_map[x])\n",
    "        self.logger.debug('After categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def smote_tomek(self,target_name):\n",
    "        '''\n",
    "        Performs SMOTETomek resampling to prevent model bias towards a majority feature.\n",
    "        \n",
    "        This function MUST be used AFTER encoding all features. Non-numeric features will raise\n",
    "        an error.\n",
    "        \n",
    "        Inputs:\n",
    "            target_name (str) - Name of the feature to be predicted (truth or target).\n",
    "            \n",
    "        Outputs:\n",
    "            None - Resampled replaces the old data.\n",
    "        '''\n",
    "        self.logger.debug('Before SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug('Before SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')\n",
    "        #Split data into features and target\n",
    "        X = self.data\n",
    "        y = self.data.pop(target_name)\n",
    "        \n",
    "        #Initialize and fit data\n",
    "        smote_tomek = SMOTETomek()\n",
    "        X_resampled, y_resampled = smote_tomek.fit_resample(X,y)\n",
    "        \n",
    "        #Concatenate data and replaced ata set.\n",
    "        self.data = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "    \n",
    "        self.logger.debug('After SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug('After SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f973c10c",
   "metadata": {},
   "source": [
    "# Pipeline class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9703b915",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLine:\n",
    "    def __init__(self,raw_data,logger,run=True,ratios=None):\n",
    "        '''\n",
    "        Initializes PipeLine class that will pass data to DataProcessor class. After a successful run\n",
    "        all data should be encoded and the data set should be resampled (if necessary).\n",
    "        \n",
    "        Inputs: \n",
    "            raw_data (pd.DataFrame) - Data set that will be encoded and resampled. Stored to retain\n",
    "                the dataset for future use and testing.\n",
    "                \n",
    "            run (bool) - If true, the pipeline will pass the data through the encoding class.\n",
    "            \n",
    "            ratios (list/tuple of list/tuples of strings) - The features to be turned into a ratio \n",
    "                are placed into a list/tuple where position 0 is the numerator and position 1 is \n",
    "                the denominator. If multiple ratios need to be taken then they can be passed \n",
    "                as a list of lists.\n",
    "                \n",
    "                [(feat1,feat2),(feat3,feat4)] will give the rations feat1/feat2 and feat3/feat4.\n",
    "    \n",
    "        '''\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        logger.info('Initializing PipeLine class')\n",
    "        logger.debug('Raw Data Shape: {self.raw_data.shape}')\n",
    "        logger.debug('Raw Data Features: {self.raw_data.columns}')\n",
    "        \n",
    "        self.raw_data = raw_data\n",
    "        self.ratios = ratios\n",
    "        self.parameter_loader()\n",
    "        \n",
    "        if self.ratios == 'all':\n",
    "            self.ratios = [v for k,v in self.params['feat_ratio_names'].items()]\n",
    "            \n",
    "        if run == True:\n",
    "            self.run_pipeline()\n",
    "            \n",
    "    def parameter_loader(self):\n",
    "        self.logger.info('Loading parameter dictionary.')\n",
    "        '''\n",
    "        Generates parameter dictionary. This will be replaced later with a json or yaml loading function.\n",
    "        \n",
    "        '''\n",
    "        self.params = {\n",
    "            'feat_categories':{\n",
    "                'numerical_continuous':['TSH_Level','T3_Level','T4_Level','Nodule_Size',],\n",
    "                'ordinal':['Age'],\n",
    "                'binary':['Gender','Family_History','Radiation_Exposure','Iodine_Deficiency',\n",
    "                    'Smoking','Obesity','Diabetes','Diagnosis',],\n",
    "                'categorical_nominal':['Country','Ethnicity',],\n",
    "                'categorical_ordinal':['Thyroid_Cancer_Risk',],\n",
    "            },\n",
    "            'encoding_utils':{\n",
    "                'binary':{'Yes':1.0,'No':0.0,'Male':1.0,'Female':0.0,'Benign':0.0,'Malignant':1.0},\n",
    "                'categorical_ordinal':{'Low':0.0,'Medium':1.0,'High':2.0},\n",
    "            },\n",
    "            'train_test':{\n",
    "                'test_size':0.2,\n",
    "            },\n",
    "            'feat_ratio_names':{\n",
    "                'ratio_1':['TSH_Level','T3_Level'],\n",
    "                'ratio_2':['Nodule_Size','T4_Level'],\n",
    "                'ratio_3':['TSH_Level','T4_Level'],\n",
    "                'ratio_4':['Nodule_Size','T3_Level']\n",
    "            },\n",
    "            'resample':'SMOTETomek',\n",
    "            'target_name':'Diagnosis',\n",
    "            \n",
    "        }\n",
    "        self.logger.info('Parameter file loaded successfully.')\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.logger.info('Initializing DataProcessor class.')\n",
    "        #Initialize data processing class\n",
    "        data_processor = DataProcessor(data=self.raw_data,logger=self.logger, params=self.params)\n",
    "        self.logger.info('DataProcessor class initialized successfully.')\n",
    "        \n",
    "        \n",
    "        #Make ratio features\n",
    "        if self.ratios:\n",
    "            self.logger.info('Creating ratios of features.')\n",
    "            for ratio in self.ratios:\n",
    "                data_processor.feat_ratios(ratio[0],ratio[1])\n",
    "            self.logger.info('Ratio features created successfully.')\n",
    "        \n",
    "        #Encode binary features\n",
    "        self.logger.info('Encoding binary features.')\n",
    "        data_processor.encode_binaries(\n",
    "            binary_feats=self.params['feat_categories']['binary'],\n",
    "            binary_map=self.params['encoding_utils']['binary'],\n",
    "        )\n",
    "        self.logger.info('Binary features encoded successfully.')\n",
    "        \n",
    "        #Encode categorical nominal features\n",
    "        self.logger.info('Begin encoding categorical nominal features.')\n",
    "        data_processor.encode_catnoms(\n",
    "            catnom_feats=self.params['feat_categories']['categorical_nominal'],\n",
    "        )\n",
    "        self.logger.info('Categorical nominal features encoded successfully.')\n",
    "        \n",
    "        self.logger.info('Begin encoding catagorical ordinal features.')\n",
    "        data_processor.encode_catords(\n",
    "            catord_feats=self.params['feat_categories']['categorical_ordinal'],\n",
    "            catord_map=self.params['encoding_utils']['categorical_ordinal'],\n",
    "        )\n",
    "        self.logger.info('Categorical ordinal features encoded successfully.')\n",
    "        \n",
    "        \n",
    "        if self.params['resample'] == 'SMOTETomek':\n",
    "            self.logger.info('Begin resampling of data.')\n",
    "            data_processor.smote_tomek(target_name=self.params['target_name'])\n",
    "            self.logger.info('Resampling of data completed successfully.')\n",
    "        \n",
    "        self.data = data_processor.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a1bb8dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 13:24:08,478 - INFO - Initializing PipeLine class\n",
      "2025-03-28 13:24:08,479 - INFO - Loading parameter dictionary.\n",
      "2025-03-28 13:24:08,480 - INFO - Parameter file loaded successfully.\n",
      "2025-03-28 13:24:08,481 - INFO - Initializing DataProcessor class.\n",
      "2025-03-28 13:24:08,482 - INFO - Initlizizing DataProcessor class\n",
      "2025-03-28 13:24:08,483 - INFO - DataProcessor class initialized successfully.\n",
      "2025-03-28 13:24:08,484 - INFO - Creating ratios of features.\n",
      "2025-03-28 13:24:08,492 - INFO - Ratio features created successfully.\n",
      "2025-03-28 13:24:08,493 - INFO - Encoding binary features.\n",
      "2025-03-28 13:24:08,918 - INFO - Binary features encoded successfully.\n",
      "2025-03-28 13:24:08,919 - INFO - Begin encoding categorical nominal features.\n",
      "2025-03-28 13:24:09,224 - INFO - Categorical nominal features encoded successfully.\n",
      "2025-03-28 13:24:09,225 - INFO - Begin encoding catagorical ordinal features.\n",
      "2025-03-28 13:24:09,284 - INFO - Categorical ordinal features encoded successfully.\n",
      "2025-03-28 13:24:09,285 - INFO - Begin resampling of data.\n",
      "2025-03-28 13:28:16,393 - INFO - Resampling of data completed successfully.\n"
     ]
    }
   ],
   "source": [
    "pipeline = PipeLine(raw_data=deepcopy(df),logger=logger,ratios='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "205cdf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Patient_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Family_History</th>\n",
       "      <th>Radiation_Exposure</th>\n",
       "      <th>Iodine_Deficiency</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>TSH_Level</th>\n",
       "      <th>...</th>\n",
       "      <th>Country_Nigeria</th>\n",
       "      <th>Country_Russia</th>\n",
       "      <th>Country_South Korea</th>\n",
       "      <th>Country_UK</th>\n",
       "      <th>Country_USA</th>\n",
       "      <th>Ethnicity_Asian</th>\n",
       "      <th>Ethnicity_Caucasian</th>\n",
       "      <th>Ethnicity_Hispanic</th>\n",
       "      <th>Ethnicity_Middle Eastern</th>\n",
       "      <th>Diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.83</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>86</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Patient_ID  Age  Gender  Family_History  Radiation_Exposure  \\\n",
       "0           1   66     1.0             0.0                 1.0   \n",
       "1           2   29     1.0             0.0                 1.0   \n",
       "2           3   86     1.0             0.0                 0.0   \n",
       "3           4   75     0.0             0.0                 0.0   \n",
       "4           5   35     0.0             1.0                 1.0   \n",
       "\n",
       "   Iodine_Deficiency  Smoking  Obesity  Diabetes  TSH_Level  ...  \\\n",
       "0                0.0      0.0      0.0       0.0       9.37  ...   \n",
       "1                0.0      0.0      0.0       0.0       1.83  ...   \n",
       "2                0.0      0.0      0.0       0.0       6.26  ...   \n",
       "3                0.0      0.0      0.0       0.0       4.10  ...   \n",
       "4                0.0      0.0      0.0       0.0       9.10  ...   \n",
       "\n",
       "   Country_Nigeria  Country_Russia  Country_South Korea  Country_UK  \\\n",
       "0              0.0             1.0                  0.0         0.0   \n",
       "1              0.0             0.0                  0.0         0.0   \n",
       "2              1.0             0.0                  0.0         0.0   \n",
       "3              0.0             0.0                  0.0         0.0   \n",
       "4              0.0             0.0                  0.0         0.0   \n",
       "\n",
       "   Country_USA  Ethnicity_Asian  Ethnicity_Caucasian  Ethnicity_Hispanic  \\\n",
       "0          0.0              0.0                  1.0                 0.0   \n",
       "1          0.0              0.0                  0.0                 1.0   \n",
       "2          0.0              0.0                  1.0                 0.0   \n",
       "3          0.0              1.0                  0.0                 0.0   \n",
       "4          0.0              0.0                  0.0                 0.0   \n",
       "\n",
       "   Ethnicity_Middle Eastern  Diagnosis  \n",
       "0                       0.0        0.0  \n",
       "1                       0.0        0.0  \n",
       "2                       0.0        0.0  \n",
       "3                       0.0        0.0  \n",
       "4                       0.0        0.0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0ef107",
   "metadata": {},
   "source": [
    "# Model 0 - All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9ff61b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.94      0.89     30551\n",
      "         1.0       0.93      0.83      0.88     30366\n",
      "\n",
      "    accuracy                           0.89     60917\n",
      "   macro avg       0.89      0.89      0.89     60917\n",
      "weighted avg       0.89      0.89      0.89     60917\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = deepcopy(pipeline.data)\n",
    "y = X.pop('Diagnosis')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "\n",
    "model_1 = RandomForestClassifier()\n",
    "model_1.fit(X_train, y_train)\n",
    "\n",
    "preds_1 = model_1.predict(X_test)\n",
    "\n",
    "report_1 = classification_report(y_test, preds_1)\n",
    "print(report_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6bcc1cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_select(data, drop_list, ohe_feats, target):\n",
    "    data.drop(columns=drop_list,inplace=True,axis=1)\n",
    "    for feat in ohe_feats:\n",
    "        data.drop(columns=df.filter(like=feat+'_').columns, inplace=True)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a19bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
