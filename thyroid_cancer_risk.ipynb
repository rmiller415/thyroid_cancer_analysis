{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de3ad0a-626e-4625-8e66-607b66a22e46",
   "metadata": {},
   "source": [
    "# Thyroid Cancer Detection Using Machine Learning Classifiers\n",
    "\n",
    "In this notebook I will be prototyping several machine learning algorithms and data cleaning/engineering methods to predict whether a patient has thyroid cancer from several features in their medical records such as: Thyroid Stimulating Hormone (TSH), T3 and T4 hormone levels, family history, size of nodules on the thyroid, radiation exposure, and other features.\n",
    "\n",
    "I will start by doing some simple informative exploratory data analysis, followed by data cleaning, model building, and finally compairson of models. I will build a class to use as a pipeline for preprocessing data, a wrapper class to call the preprocessing pipeline, a class and function for model training, and finally a function for model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b88b6f-0fee-4a15-ba54-675eb300204e",
   "metadata": {},
   "source": [
    "# Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c89865f2-95bb-4c51-855e-7426534ebfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functionality packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import joblib\n",
    "import math\n",
    "import dill\n",
    "from copy import deepcopy\n",
    "\n",
    "#Preprocessing packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "#Import Classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#Import classifier utilities\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Import calculators and metrics\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Other Utilities \n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f9f503-ecdb-4d31-bed3-1b8bfd009afe",
   "metadata": {},
   "source": [
    "### Check Dataset for Irregularities and NaNs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984155b-28a1-4ccb-b615-e6f3ec3b8edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "pc_fpath = 'C:\\\\Users\\\\rwmil\\\\Downloads\\\\thyroid_cancer_risk_data.csv'\n",
    "data = pd.read_csv(mac_fpath)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a655d504-93ca-41d7-80b7-9f91e5d09c89",
   "metadata": {},
   "source": [
    "## Ensure the data is correctly formatted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1627ed-49c2-4cf7-8200-24a1291ce12f",
   "metadata": {},
   "source": [
    "### Check for duplicate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696d366-9f25-47c4-8206-54da3c1c49ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_duplicates = data[data.duplicated()].shape\n",
    "print(f\"There are {data_duplicates[0]} duplicate entries and {data_duplicates[1]} features in the data set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befd6f9a-7e20-48ea-b65c-1c9687b0bb09",
   "metadata": {},
   "source": [
    "### Define parameter dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee47d9-d0d9-4a79-a2d8-3a6a02b5620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'feat_categories':{\n",
    "        'numerical_continuous':['TSH_Level','T3_Level','T4_Level','Nodule_Size'],\n",
    "        'ordinal':['Age'],\n",
    "        'binary':['Gender','Family_History','Radiation_Exposure','Iodine_Deficiency','Smoking','Obesity','Diabetes'],\n",
    "        'categorical_nominal':['Country','Ethnicity'],\n",
    "        'categorical_ordinal':['Thyroid_Cancer_Risk']\n",
    "        },\n",
    "    'data_types':{\n",
    "        'TSH_Level':float,\n",
    "        'T3_Level':float,\n",
    "        'T4_Level':float,\n",
    "        'Nodule_Size':float,\n",
    "        'Age':int,\n",
    "        'Gender':str,\n",
    "        'Family_History':str,\n",
    "        'Radiation_Exposure':str,\n",
    "        'Iodine_Deficiency':str,\n",
    "        'Smoking':str,\n",
    "        'Obesity':str,\n",
    "        'Diabetes':str,\n",
    "        'Country':str,\n",
    "        'Ethnicity':str,\n",
    "        'Thyroid_Cancer_Risk':str,\n",
    "    },\n",
    "    'encoding_utils':{\n",
    "        'binary':{'Yes':1.0,'No':0.0,'Male':1.0,'Female':0.0,'Benign':0.0,'Malignant':1.0},\n",
    "        'categorical_ordinal':{'Low':0.0,'Medium':1.0,'High':2.0},\n",
    "    },\n",
    "    'train_test':{\n",
    "        'test_size':0.2,\n",
    "    },\n",
    "    'feat_ratio_names':{\n",
    "        'ratio_1':['TSH_Level','T3_Level'],\n",
    "        'ratio_2':['Nodule_Size','T4_Level'],\n",
    "        'ratio_3':['TSH_Level','T4_Level'],\n",
    "        'ratio_4':['Nodule_Size','T3_Level']\n",
    "    },\n",
    "    'resample':'SMOTETomek',\n",
    "    'target_name':'Diagnosis',\n",
    "    'Thyroid_Cancer_Risk':['Low','Medium','High',],\n",
    "    'allowables':{\n",
    "        'TSH_Level':None,\n",
    "        'T3_Level':None,\n",
    "        'T4_Level':None,\n",
    "        'Nodule_Size':None,\n",
    "        'Age':None,\n",
    "        'Gender':['Male','Female'],\n",
    "        'Family_History':['Yes','No'],\n",
    "        'Radiation_Exposure':['Yes','No'],\n",
    "        'Iodine_Deficiency':['Yes','No'],\n",
    "        'Smoking':['Yes','No'],\n",
    "        'Obesity':['Yes','No'],\n",
    "        'Diabetes':['Yes','No'],\n",
    "        'Country':[\n",
    "            'Russia',\n",
    "            'Germany',\n",
    "            'Nigeria',\n",
    "            'India',\n",
    "            'UK',\n",
    "            'South Korea',\n",
    "            'Brazil',\n",
    "            'China',\n",
    "            'Japan',\n",
    "            'USA',\n",
    "        ],\n",
    "        'Ethnicity':[\n",
    "            'Caucasian',\n",
    "            'Hispanic',\n",
    "            'Asian',\n",
    "            'African',\n",
    "            'Middle Eastern',\n",
    "        ],\n",
    "        'Thyroid_Cancer_Risk':['Low','Medium','High']\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021e567-4b36-4460-920d-df64340b28db",
   "metadata": {},
   "source": [
    "### Define function to check data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25109359-812c-4a6a-b738-9e5c9dc2fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type_check(data, params):\n",
    "    '''\n",
    "    Iterates through features list. Checks for nans, entry data types, and \n",
    "    allowed values in each feature column.\n",
    "    \n",
    "    Prints results.\n",
    "    Returns nothing.\n",
    "    '''\n",
    "    for key,value in params['feat_categories'].items():\n",
    "        for item in value:\n",
    "            data_type = params['data_types'][item]\n",
    "            allowables = params['allowables'][item]\n",
    "\n",
    "            print(f'{item} has nan values? {data[item].isna().any()}')\n",
    "            print(f\"{item} has invalid data types? {(~data[item].map(lambda x: isinstance(x, data_type))).any()}\")\n",
    "            if allowables is not None:\n",
    "                print(f\"{item} has invalid values? {(~data[item].map(lambda x: x in allowables)).any()}\")\n",
    "                print(' ')\n",
    "            else:\n",
    "                print(' ')\n",
    "\n",
    "data_type_check(data, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb6d64-d239-4448-88d2-1b35c0ebda93",
   "metadata": {},
   "source": [
    "There are no missing/NaN values and all feature entries are of the correct type or are within range. Moving on to exploratory data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253e2d4-4645-4728-bba1-d62cffc3fd02",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3b4799-df46-4f22-9a23-9e8eebc7474d",
   "metadata": {},
   "source": [
    "## Continuous Data EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbdabc3-ab15-4ba3-96f5-663da06263c1",
   "metadata": {},
   "source": [
    "### Histplots with Kernel-Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f04b15a-8d9e-4e29-bb13-a1dd170e861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plot size variables\n",
    "X = deepcopy(data)\n",
    "y = X.pop('Diagnosis')\n",
    "num_feats = len(params['feat_categories']['numerical_continuous'])\n",
    "num_rows = math.ceil(math.sqrt(num_feats))\n",
    "num_cols = math.ceil(num_feats/num_rows)\n",
    "n=3\n",
    "#Initialize plot\n",
    "fig,axs = plt.subplots(nrows=num_rows,ncols=num_cols,sharey=False,constrained_layout=True,figsize=((n+1)*num_rows,n*num_cols))\n",
    "\n",
    "#Plot histogram\n",
    "for i,ax in enumerate(axs.flat):\n",
    "    feat_name = params['feat_categories']['numerical_continuous'][i]\n",
    "    x = data[feat_name].to_numpy()\n",
    "    sns.histplot(\n",
    "        x=feat_name,\n",
    "        hue='Diagnosis',\n",
    "        data=df,\n",
    "        ax=ax,\n",
    "        color='orchid',\n",
    "        kde=True,\n",
    "        bins=int(np.log2(len(x))+1),\n",
    "        element='step',\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=df,\n",
    "        x=feat_name,\n",
    "        hue='Diagnosis',\n",
    "        ax=ax,\n",
    "        common_norm=False\n",
    "    )\n",
    "    \n",
    "    ax.set_title(feat_name)\n",
    "    ax.set_xlabel('concentration')\n",
    "    \n",
    "\n",
    "plt.show()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3404d50-4558-4e60-a7b9-afb38ca5d19d",
   "metadata": {},
   "source": [
    "### Box and Whisker Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a808a0-ff35-4915-a11c-53180a54d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define plot size variables\n",
    "y = df['Diagnosis']\n",
    "num_feats = len(params['feat_categories']['numerical_continuous'])\n",
    "num_rows = math.ceil(math.sqrt(num_feats))\n",
    "num_cols = math.ceil(num_feats/num_rows)\n",
    "#Initialize subplots\n",
    "fig,axs = plt.subplots(nrows=num_rows,ncols=num_cols,constrained_layout=True,)\n",
    "\n",
    "for i,ax in enumerate(axs.flat):\n",
    "    feat_name = params['feat_categories']['numerical_continuous'][i]\n",
    "    x = df[feat_name].to_numpy()\n",
    "    sns.boxplot(x=x,y=y,ax=ax,color='coral')\n",
    "    ax.set_title(feat_name)\n",
    "    ax.set_xlabel('concentration')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde0fcba-428a-447f-b3f5-b8c8e88ff90d",
   "metadata": {},
   "source": [
    "### t-test on continuous variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e5a6b-7286-453d-af64-c86f7d2c8626",
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = df[df['Diagnosis'] == 'Benign']\n",
    "malignant = df[df['Diagnosis'] == 'Malignant']\n",
    "\n",
    "for feat in params['feat_categories']['numerical_continuous']:\n",
    "    stat,p = ttest_ind(benign[feat],malignant[feat],equal_var=False)\n",
    "    \n",
    "    print(f\"{feat}: t-test score = {stat:.4f}, p-value is {p:.4f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f17941-d1a3-4cce-8b4c-e60e4204638f",
   "metadata": {},
   "source": [
    "The distribution of TSH_Level, T3_Level, and T4_Level all appear to be pretty uniform for both malignant and benign. I don't believe there is much predictive power in these three features. But histplots and box-and-whisker plots only find linear relationships between feature and target. But, it looks like Nodule_Size might hold some predictive power, the p-value for nodule size seems to indicate this.\n",
    "\n",
    "**Next steps: Attempt to transform these features using log2, log10, or sqrt.**\n",
    "\n",
    "\n",
    "**Future Steps: During model training, I will try ratios of these feats and see if they show any predictive power.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f721019-c0fe-4e08-8189-6bd4154a1571",
   "metadata": {},
   "source": [
    "### Pairplots (Non-Transformed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e4adf4-c6a2-4c2f-9ddb-10b1aa2ff9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.sample(frac=0.01),corner=True,hue='Diagnosis',vars=params['feat_categories']['numerical_continuous'],plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf515c25-d4fe-4e3d-a40c-e59af8aeed5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data with log2 and sqrt\n",
    "feat_names_log_transform = [i+'_log_transformed' for i in params['feat_categories']['numerical_continuous']]\n",
    "feat_names_sqrt_transform = [i+'_sqrt_transformed' for i in params['feat_categories']['numerical_continuous']]\n",
    "\n",
    "data[feat_names_log_transform] = data[params['feat_categories']['numerical_continuous']].apply(lambda x: np.log2(x))\n",
    "data[feat_names_sqrt_transform] = data[params['feat_categories']['numerical_continuous']].apply(lambda x: np.sqrt(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89771798-c1a4-430d-8009-e980515c73a5",
   "metadata": {},
   "source": [
    "### Pairplots (Log2 Transformed Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8833bac-fde8-4cfe-bf1a-6752d543c453",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.sample(frac=0.01),corner=True,hue='Diagnosis',vars=feat_names_log_transform,plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b20b41-4560-42d5-bf68-2487ae326b0d",
   "metadata": {},
   "source": [
    "### Pairplots (Sqrt Transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e55231e-f1ad-4564-875b-daa8eb659b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data.sample(frac=0.01),corner=True,hue='Diagnosis',vars=feat_names_sqrt_transform,plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b201e0-1ae1-482f-adac-58a0111913a1",
   "metadata": {},
   "source": [
    "The transforms show some skew in the data, except for T4_Level. It might be worth training a few models with log2 and sqrt transforms on the data. Log2 gives a more skewed Gaussian look than sqrt doe,s and I think models like RandomForestClassifier will have an easier time finding patterns in those.\n",
    "\n",
    "**Future Steps: Train a model with log2 feats and compare to other models.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5d6129-21d9-4cc0-a462-7652d4f17173",
   "metadata": {},
   "source": [
    "## Categorical Ordinal Feature EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abad4510-6033-45fa-b2dd-72b5444e0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get categorical feat names\n",
    "ordinal_feats = params['feat_categories']['categorical_ordinal']\n",
    "data_ = pd.read_csv(pc_fpath)\n",
    "data[ordinal_feats] = data_[ordinal_feats]\n",
    "#Encode ordinal feats\n",
    "ordinal_encoding_dict = {'Low':0,'Medium':1,'High':2}\n",
    "data[ordinal_feats] = data[ordinal_feats].map(lambda x:ordinal_encoding_dict[x])\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,6))\n",
    "\n",
    "sns.barplot(\n",
    "    data=data,\n",
    "    x='Thyroid_Cancer_Risk',\n",
    "    y=(data['Diagnosis']=='Malignant').astype(int),\n",
    "    order=[0,1,2],\n",
    "    ax=ax[0]\n",
    ")\n",
    "\n",
    "ax[0].set_ylabel('Malignant Counts')\n",
    "ax[0].set_title('Malignancy Rate by Thyroid Cancer Risk')\n",
    "\n",
    "sns.barplot(\n",
    "    data=data,\n",
    "    x='Thyroid_Cancer_Risk',\n",
    "    y=(data['Diagnosis']=='Benign').astype(int),\n",
    "    order=[0,1,2],\n",
    "    ax=ax[1]\n",
    ")\n",
    "\n",
    "ax[1].set_ylabel('Benign Counts')\n",
    "ax[1].set_title('Benign Rate by Thyroid Cancer Risk')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd4aa6-a573-4f35-9bc7-99f327417dc7",
   "metadata": {},
   "source": [
    "It's pretty clear form the two graphs above that the Thyroid_Cancer_Risk feature is a good feature. If you are at a 2 (high) risk, then you have a high chance of malignancy. Where as being at a 0 (low) or a 1 (modelate) your risk of malignancy is much lower. This feature can be kept without any transformations other than encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9a5a3b-4782-4106-86b4-daec17ece21e",
   "metadata": {},
   "source": [
    "# Categorical Nominal Feature EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a4efbf-ec27-4d16-8e57-373fd25b0cc6",
   "metadata": {},
   "source": [
    "### Frequency Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018e40f-a8db-402f-a637-2ff75c70123e",
   "metadata": {},
   "source": [
    "### Define function to make frequency plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d378e5-2be1-4454-be69-e7cc5f1595d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_bar_plotter(data,target,feats_list,normalize=True):\n",
    "    \n",
    "    #Get names and counts of all unique target values\n",
    "    unique_targets = list(data[target].unique())\n",
    "    unique_target_counts = [data[data[target]==i].shape[0] for i in unique_targets]\n",
    "    num_counts = data.shape[0] \n",
    "    results = []\n",
    "\n",
    "    #Initialize plot area\n",
    "    num_rows = math.ceil(math.sqrt(len(feats_list)*len(unique_targets)))\n",
    "    num_cols = math.ceil((len(feats_list)*len(unique_targets))/num_rows)\n",
    "    n=3\n",
    "    fig,axs = plt.subplots(num_rows, num_cols, figsize=((n+1)*num_rows,n*num_cols))\n",
    "\n",
    "    \n",
    "    for feat in feats_list:\n",
    "        #Get labels and ticks for a feat.\n",
    "        xlabels = list(data[feat].unique())\n",
    "        xticks = [list(range(len(i))) for i in xlabels]\n",
    "        \n",
    "        #Calculate normalized percentage\n",
    "        if normalize == True:\n",
    "            \n",
    "            #Calculate values for all targets\n",
    "            num_counts = data.shape[0] #total number of counts\n",
    "            unique_target_vals = data[target].unique()\n",
    "            unique_feat_vals = data[feat].unique()\n",
    "            unique_feat_counts = data[feat].value_counts().to_numpy() #number of counts for each unique entry in the feature for all target values\n",
    "            unique_feat_idxs = list(range(len(unique_feat_counts)))\n",
    "            #Get values for each unique target value\n",
    "            #Calculate values\n",
    "            for idx,val in enumerate(unique_target_vals):\n",
    "                num_unique_target_counts = len(data[data[target]==val]) #number of total counts for each unique feat entry for one of the target values\n",
    "                target_counts_by_feat = data[data[target]==val][feat].value_counts().to_numpy() #number of counts for each unique feat entry for each unique target value\n",
    "\n",
    "                #Calculations\n",
    "                top = target_counts_by_feat/num_unique_target_counts\n",
    "                bottom = unique_feat_counts/num_counts\n",
    "                result = top/bottom\n",
    "\n",
    "                #Store calculations and their results\n",
    "                results.append((unique_feat_vals,feat,target,val,result,))\n",
    "\n",
    "    else:\n",
    "        for feat in feats_list:\n",
    "            unique_feat_vals = data[feat].unique()\n",
    "            for val in unique_targets:\n",
    "                results.append((unique_feat_vals,feat,target,val,data[feat].to_numpy()))\n",
    "        \n",
    "\n",
    "    for i,ax in enumerate(axs.flat):\n",
    "        sns.countplot(x=results[i][-1],ax=ax)\n",
    "        ax.set_xticks(list(range(len(results[i][0]))))\n",
    "        ax.set_xticklabels(results[i][0],rotation=90)\n",
    "        ax.set_title(results[i][2]+':'+results[i][3]+' Counts by '+results[i][1])\n",
    "        if normalize == True:\n",
    "            ax.set_ylim(min(results[i][-1])-0.01,max(results[i][-1]+0.01))\n",
    "            ax.set_ylabel('Normalized Counts')\n",
    "\n",
    "        else:\n",
    "            ax.set_ylabel('Raw Counts')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cdeb0-376f-457a-969a-4e184043771b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = normalized_bar_plotter(data=data,target='Diagnosis',feats_list=['Country','Ethnicity'],normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27caa17a-82dc-45c6-ae8a-64f2d8730e86",
   "metadata": {},
   "source": [
    "The number of benign and malignant counts is highest in India, so it might be tempting to think that being from India increases your chance of being diagnosed with thyroid cancer. But at the same time, it increases your chances of a benign result, too, and that doesn't make much sense. India does account for the majority of the data points by far. So, I think it would be better to get a weighted average based on how much each country or ethnicity contributes to the total dataset.\n",
    "\n",
    "When I saw these results I was initially inspired by the idea of a weighted average similar to how the average atomic mass is calculated for each element. Avg. Mass = $\\Sigma _i^Np_im_i$\n",
    "\n",
    "Where $p_i$ is the percent abundance of an isotope and $m_i$ is the mass of the isotope.\n",
    "\n",
    "\n",
    "\n",
    "For this problem, $p_i$ is the percentage of diagnosis counts divided by the total number of counts for that diagnosis across all countries: $p_i = \\frac{d_i}{D}$ \n",
    "\n",
    "and the \"mass\" (or more appropriately the average risk) of each country is the percentage of counts (both malignant and benign) out of all country counts (both malignant or benign) $m_i=\\frac{C}{c_i}$. \n",
    "\n",
    "Where $d_i$ is the number of counts for a diagnosis in the $i-$th country, $D$ is the total counts for that diagnosis (e.g., Malignant or Benign), $c_i$ is the total number of all counts from that country, and $C$ is the total counts of all countries.\n",
    "\n",
    "And the average risk can be calculated by $\\frac{d_i\\cdot C}{c_i\\cdot D}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11656bb-684c-4523-b4e4-f4120a9061ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = normalized_bar_plotter(data=data,target='Diagnosis',feats_list=['Country','Ethnicity'],normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb13e97e-b544-4e37-8962-9aac478225a6",
   "metadata": {},
   "source": [
    "We can see that plotting the count frequency by weight gives a relatively flat distribution. In other words, there isn't much difference between any two countries or ethnicities. Therefore, I don't believe that these features have any predictive power, so I will be dropping them.\n",
    "\n",
    "**Next Step: Move on to binary feature EDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882f0b0-38a2-48c0-b8a9-ba70db76f372",
   "metadata": {},
   "source": [
    "## Binary Features EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1d1dd2-8095-4900-9b99-5c274ed8939e",
   "metadata": {},
   "source": [
    "### Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fca0e21-a2b6-4d87-befd-fc5eda0f9eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_list = deepcopy(params['feat_categories']['binary'])\n",
    "binary_data = data[binary_list].map(lambda x:params['encoding_utils']['binary'][x])\n",
    "sns.heatmap(binary_data.corr(),cmap='coolwarm',annot=True,fmt='.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40196813-621f-4a04-b57c-4b880fac446b",
   "metadata": {},
   "source": [
    "It looks like there is some predictive power in the family history, radiation exposure, and iodine deficiency features. But the rest seems really small. However, the correlation coefficient only shows linear relationships. Because the features are easy to encode and work with I will keep them all. I might train a model without Gender, Smoking, Obesity, and Diagnosis to compare them. But I think leaving them in will at least add some randomness and reduce overfitting.\n",
    "\n",
    "**Future Steps: Train models with and without smoking, obesity, gender, and diabetes. Compare the results**\n",
    "\n",
    "The only remaining feature to explore is age. But I will not be doing any analysis because cancer is probabilistic in nature and as time increases, the number of cancer-causing events also increases. In general, it's safe to say that as you get older, your risk of developing cancer increases. So, I will keep the age feature without any transformation or analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c07d40a-597c-4b3c-bc46-254e68b4cd67",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8525635a-c335-472b-93c0-ea207a7e3b2c",
   "metadata": {},
   "source": [
    "## Reload Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e1a128-2997-4185-b199-9b293caae35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac_fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "pc_fpath = 'C:\\\\Users\\\\rwmil\\\\Downloads\\\\thyroid_cancer_risk_data.csv'\n",
    "data = pd.read_csv(mac_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e260cd10-29e1-465f-91c6-c2ca4386c821",
   "metadata": {},
   "source": [
    "## Define Data Processing Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bad31920-39a1-4b17-a00b-d40c29d7666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##PACKAGE LIST\n",
    "#pandas\n",
    "#logging\n",
    "#sklearn.preprocessing OneHotEncoder\n",
    "#imblearn.combine SMOTETomek\n",
    "class DataProcessor:\n",
    "    def __init__(self,data,params,logger):\n",
    "        self.logger = logger\n",
    "        self.logger.info('Initlizizing DataProcessor class')\n",
    "        \n",
    "        self.data = data\n",
    "        self.params = params\n",
    "        self.logger = logger\n",
    "\n",
    "        \n",
    "    def feat_ratios(self,top,bottom):\n",
    "        self.logger.debug(f'Before ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'Before ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        '''Creates a new features by dividing two numerical features.\n",
    "\n",
    "        Inputs: top (string) - name of feature in dataset to be in the numerator of the ratio.\n",
    "                bottom (string) - name of feature in dataset to be in the denominator of the ratio.\n",
    "\n",
    "        Outputs: None - Appends new feature to the dataset, self.data.\n",
    "        \n",
    "        '''\n",
    "        #Divide top/bottom features\n",
    "        new_feat = top+':'+bottom\n",
    "        self.data[new_feat] = self.data[top]/self.data[bottom]\n",
    "        self.logger.debug(f'After ratio encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'After ratio encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_binaries(self,binary_feats,binary_map):\n",
    "        '''Encodes binary feats in a data set using the binary map dictionary. Entries in each feature\n",
    "            must be keys in the dictionary and will be replaced by the corresponding value in the dictionary.\n",
    "        \n",
    "        Inputs:\n",
    "            binary_feats (list of strings) - list containing strings with binary features \n",
    "            from the data set to be encoded.\n",
    "            \n",
    "            binary_maps (dictionary) - dictionary that has keys (string) corresponding to \n",
    "            entries in a binary feature. The values (int) of the dictionary will replace \n",
    "            the corresponding keys.\n",
    "        \n",
    "        Outputs:\n",
    "            None - Replaces the feature with a binary encoded feature in the dataset (self.data).\n",
    "        '''\n",
    "        self.logger.debug(f'Before binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'Before binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        self.data[binary_feats] = self.data[binary_feats].map(lambda x: binary_map[x])\n",
    "        self.logger.debug(f'After binary encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'After binary encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "    def encode_catnoms(self, catnom_feats, encode_type='one_hot'):\n",
    "        '''\n",
    "        Performs encoding on categorical nominal features. Currently only supports one hot encoding.\n",
    "        \n",
    "        Inputs:\n",
    "            catnom_feats (list of strings) - Each string in the list is the name of a categorical \n",
    "            nominal feature to be encoded.\n",
    "            \n",
    "            encode_type (str) - Type of encoding to be performed on categorical nominal features.\n",
    "                Currently only one hot encoding is implimented.\n",
    "                \n",
    "        Outputs:\n",
    "            None - appends the encoded features to the data set (self.data) and drops the unencoded\n",
    "            features.\n",
    "        \n",
    "        '''\n",
    "        self.logger.debug(f'Before categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'Before categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        if encode_type == 'one_hot':\n",
    "            #Initialize encoder and fit transform\n",
    "            ohe_encoder = OneHotEncoder(drop='first',sparse_output=False,handle_unknown='ignore')\n",
    "            ohe_encoded = ohe_encoder.fit_transform(self.data[catnom_feats])\n",
    "            col_names = ohe_encoder.get_feature_names_out(catnom_feats)\n",
    "            encoded_feats = pd.DataFrame(ohe_encoded,columns=col_names)\n",
    "\n",
    "            #Reset indices to ensure alignment of the dataframe\n",
    "            #then concatenate data with encoded feats\n",
    "            self.data.reset_index(drop=True,inplace=True)\n",
    "            encoded_feats.reset_index(drop=True,inplace=True)\n",
    "            self.data = pd.concat([self.data,encoded_feats],axis=1)\n",
    "            \n",
    "            #Drop unencoded features to prevent issues with resampling and model fitting.\n",
    "            self.data.drop(columns=catnom_feats,axis=1,inplace=True)\n",
    "        self.logger.debug('After categorical nominal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('After categorical nominal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        \n",
    "    def encode_catords(self,catord_feats,catord_map):\n",
    "        '''\n",
    "        Encodes categorical ordinal features using a mapping dictionary. Replaces the unencoded features\n",
    "        with encoded features.\n",
    "        \n",
    "        Inputs: \n",
    "            catord_feats (list of strings) - Each string in the list must be a feature name in\n",
    "                the dataset.\n",
    "                \n",
    "            catord_map (dict) - Dictionary of features containing keys (str) that are in the unencoded\n",
    "                feature and corresponding values (int) that will be replacing the unencoded entries.\n",
    "                \n",
    "        Outputs:\n",
    "            None - Replaces the unencoded feature in the dataset (self.data)\n",
    "        '''\n",
    "        self.logger.debug(f'Before categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug('fBefore categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "        #Apply encoding\n",
    "        self.data[catord_feats] = self.data[catord_feats].map(lambda x: catord_map[x])\n",
    "        self.logger.debug(f'After categorical ordinal encoding the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'After categorical ordinal encoding the number of NaNs is: {self.data.isna().sum()}')\n",
    "\n",
    "    def sqrt_transform(self,feat_list):\n",
    "        transformed_feats = ['sqrt_transformed_'+feat for feat in feat_list]\n",
    "        for i, feat in enumerate(feat_list):\n",
    "            self.data[transformed_feats[i]] = self.data[feat].map(lambda x:np.sqrt(x))\n",
    "\n",
    "    def log1p_transform(self,feat_list):\n",
    "        transformed_feats = ['log1p_transformed_'+feat for feat in feat_list]\n",
    "        for i, feat in enumerate(feat_list):\n",
    "            self.data[transformed_feats[i]] = self.data[feat].map(lambda x:np.log1p(x))\n",
    "            \n",
    "    def smote_tomek(self,target_name):\n",
    "        '''\n",
    "        Performs SMOTETomek resampling to prevent model bias towards a majority feature.\n",
    "        \n",
    "        This function MUST be used AFTER encoding all features. Non-numeric features will raise\n",
    "        an error.\n",
    "        \n",
    "        Inputs:\n",
    "            target_name (str) - Name of the feature to be predicted (truth or target).\n",
    "            \n",
    "        Outputs:\n",
    "            None - Resampled replaces the old data.\n",
    "        '''\n",
    "        self.logger.debug(f'Before SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'Before SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')\n",
    "        \n",
    "        #Split data into features and target\n",
    "        X = self.data\n",
    "        y = self.data.pop(target_name)\n",
    "\n",
    "        #Initialize and fit data\n",
    "        smote_tomek = SMOTETomek()\n",
    "        X_resampled, y_resampled = smote_tomek.fit_resample(X,y)\n",
    "        \n",
    "        #Concatenate data and replaced ata set.\n",
    "        self.data = pd.concat([X_resampled,y_resampled],axis=1)\n",
    "    \n",
    "        self.logger.debug(f'After SMOTE-Tomek resampling the features are: {self.data.columns}')\n",
    "        self.logger.debug(f'After SMOTE-Tomek resampling the number of NaNs is: {self.data.isna().sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcc14b-2d58-4ffd-a0e1-5077ae3b0111",
   "metadata": {},
   "source": [
    "## Define Data Processing Wrapper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49386415-10a0-486c-8cbe-adc976dfd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PACKAGE LIST\n",
    "#logging\n",
    "#pandas\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"pipeline.log\"),  # writes to file\n",
    "        logging.StreamHandler()               # prints to console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EncodingPipeLine:\n",
    "    def __init__(self,raw_data,logger,run=True,ratios=None):\n",
    "        '''\n",
    "        Initializes PipeLine class that will pass data to DataProcessor class. After a successful run\n",
    "        all data should be encoded and the data set should be resampled (if necessary).\n",
    "        \n",
    "        Inputs: \n",
    "            raw_data (pd.DataFrame) - Data set that will be encoded and resampled. Stored to retain\n",
    "                the dataset for future use and testing.\n",
    "                \n",
    "            run (bool) - If true, the pipeline will pass the data through the encoding class.\n",
    "            \n",
    "            ratios (list/tuple of list/tuples of strings) - The features to be turned into a ratio \n",
    "                are placed into a list/tuple where position 0 is the numerator and position 1 is \n",
    "                the denominator. If multiple ratios need to be taken then they can be passed \n",
    "                as a list of lists.\n",
    "                \n",
    "                [(feat1,feat2),(feat3,feat4)] will give the rations feat1/feat2 and feat3/feat4.\n",
    "    \n",
    "        '''\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        logger.info('Initializing PipeLine class')\n",
    "        logger.debug('Raw Data Shape: {self.raw_data.shape}')\n",
    "        logger.debug('Raw Data Features: {self.raw_data.columns}')\n",
    "        \n",
    "        self.raw_data = raw_data\n",
    "        self.ratios = ratios\n",
    "        self.parameter_loader()\n",
    "        \n",
    "        if self.ratios == 'all':\n",
    "            self.ratios = [v for k,v in self.params['feat_ratio_names'].items()]\n",
    "            \n",
    "        if run == True:\n",
    "            self.run_pipeline()\n",
    "            \n",
    "    def parameter_loader(self):\n",
    "        self.logger.info('Loading parameter dictionary.')\n",
    "        '''\n",
    "        Generates parameter dictionary. This will be replaced later with a json or yaml loading function.\n",
    "        \n",
    "        '''\n",
    "        self.params = {\n",
    "            'feat_categories':{\n",
    "                'numerical_continuous':['TSH_Level','T3_Level','T4_Level','Nodule_Size',],\n",
    "                'ordinal':['Age'],\n",
    "                'binary':['Gender','Family_History','Radiation_Exposure','Iodine_Deficiency',\n",
    "                    'Smoking','Obesity','Diabetes','Diagnosis',],\n",
    "                'categorical_nominal':['Country','Ethnicity',],\n",
    "                'categorical_ordinal':['Thyroid_Cancer_Risk',],\n",
    "            },\n",
    "            'encoding_utils':{\n",
    "                'binary':{'Yes':1.0,'No':0.0,'Male':1.0,'Female':0.0,'Benign':0.0,'Malignant':1.0},\n",
    "                'categorical_ordinal':{'Low':0.0,'Medium':1.0,'High':2.0},\n",
    "            },\n",
    "            'train_test':{\n",
    "                'test_size':0.2,\n",
    "            },\n",
    "            'feat_ratio_names':{\n",
    "                'ratio_1':['TSH_Level','T3_Level'],\n",
    "                'ratio_2':['Nodule_Size','T4_Level'],\n",
    "                'ratio_3':['TSH_Level','T4_Level'],\n",
    "                'ratio_4':['Nodule_Size','T3_Level']\n",
    "            },\n",
    "            'resample':'SMOTETomek',\n",
    "            'target_name':'Diagnosis',\n",
    "            \n",
    "        }\n",
    "        self.logger.info('Parameter file loaded successfully.')\n",
    "        \n",
    "    def run_pipeline(self):\n",
    "        self.logger.info('Initializing DataProcessor class.')\n",
    "        #Initialize data processing class\n",
    "        data_processor = DataProcessor(data=self.raw_data,logger=self.logger, params=self.params)\n",
    "        self.logger.info('DataProcessor class initialized successfully.')\n",
    "        \n",
    "        \n",
    "        #Make ratio features\n",
    "        if self.ratios:\n",
    "            self.logger.info('Creating ratios of features.')\n",
    "            for ratio in self.ratios:\n",
    "                data_processor.feat_ratios(ratio[0],ratio[1])\n",
    "            self.logger.info('Ratio features created successfully.')\n",
    "        \n",
    "        #Encode binary features\n",
    "        self.logger.info('Encoding binary features.')\n",
    "        data_processor.encode_binaries(\n",
    "            binary_feats=self.params['feat_categories']['binary'],\n",
    "            binary_map=self.params['encoding_utils']['binary'],\n",
    "        )\n",
    "        self.logger.info('Binary features encoded successfully.')\n",
    "        \n",
    "        #Encode categorical nominal features\n",
    "        self.logger.info('Begin encoding categorical nominal features.')\n",
    "        data_processor.encode_catnoms(\n",
    "            catnom_feats=self.params['feat_categories']['categorical_nominal'],\n",
    "        )\n",
    "        self.logger.info('Categorical nominal features encoded successfully.')\n",
    "        \n",
    "        self.logger.info('Begin encoding catagorical ordinal features.')\n",
    "        data_processor.encode_catords(\n",
    "            catord_feats=self.params['feat_categories']['categorical_ordinal'],\n",
    "            catord_map=self.params['encoding_utils']['categorical_ordinal'],\n",
    "        )\n",
    "        self.logger.info('Categorical ordinal features encoded successfully.')\n",
    "\n",
    "        #Transform numerical continuous features\n",
    "        self.logger.info('Begin encoding numerical continuous features.')\n",
    "        data_processor.log1p_transform(self.params['feat_categories']['numerical_continuous'])\n",
    "        data_processor.sqrt_transform(self.params['feat_categories']['numerical_continuous'])\n",
    "        self.logger.info('Numerical continuous feats transformed successfully.')\n",
    "        \n",
    "        if self.params['resample'] == 'SMOTETomek':\n",
    "            self.logger.info('Begin resampling of data.')\n",
    "            data_processor.smote_tomek(target_name=self.params['target_name'])\n",
    "            self.logger.info('Resampling of data completed successfully.')\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        self.data = data_processor.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e41690f5-081b-4e9c-8d24-171068e3dbd5",
   "metadata": {},
   "source": [
    "## Define Class to Save Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21c35c44-9cee-412c-91a1-fa272c5acc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Packages:\n",
    "#pandas\n",
    "#dill\n",
    "#json\n",
    "#pathlib\n",
    "#copy\n",
    "class ModelSaver:\n",
    "    def __init__(self,algorithm,X_valid,y_valid,output_dir,iteration_start=0,notes=None,save_params=False,params=None):\n",
    "        self.algorithm = algorithm\n",
    "        self.notes = notes\n",
    "        self.output_dir = output_dir\n",
    "        self.save_params = save_params\n",
    "        self.params = params\n",
    "        self.iteration = iteration_start\n",
    "        self.model_save = {}\n",
    "        self.model_out = {}\n",
    "        self.all_model_data = {\n",
    "            'X_valid':X_valid,\n",
    "            'y_valid':y_valid,\n",
    "            'notes':notes,\n",
    "            'algorithm':[algorithm],\n",
    "        }\n",
    "        \n",
    "        if self.params != None:\n",
    "            self.all_model_data['params'] = params\n",
    "        \n",
    "        \n",
    "\n",
    "    def record_state(self, model, X_test, X_train, y_test, y_train, model_preds,model_scores,drop_list,params=None,model_notes=None):\n",
    "        current_model = {\n",
    "            'model':model,\n",
    "            'X_test':X_test,\n",
    "            'X_train':X_train,\n",
    "            'y_test':y_test,\n",
    "            'y_train':y_train,\n",
    "            'model_preds':model_preds,\n",
    "            'model_notes':model_notes,\n",
    "            'model_scores':model_scores,\n",
    "        }\n",
    "        \n",
    "        if self.save_params == True:\n",
    "            current_model['params'] = params\n",
    "            \n",
    "        \n",
    "        self.model_save[self.algorithm+'_'+str(self.iteration)] = current_model\n",
    "        self.iteration += 1\n",
    "            \n",
    "            \n",
    "    def save_state(self,output_fname,output_dir):\n",
    "            \n",
    "        self.model_out[self.algorithm] = deepcopy(self.model_save)\n",
    "        dir_path = Path(output_dir)\n",
    "        fpath = dir_path/output_fname\n",
    "        with open(fpath,'wb') as f:\n",
    "            dill.dump(self.model_out,f)\n",
    "        logging.info('Data Saved to Disk')\n",
    "    \n",
    "    def update_state(self, algorithm, iteration):\n",
    "        self.algorithm = algorithm\n",
    "        self.iteration = iteration\n",
    "        self.model_out[self.algorithm] = deepcopy(self.model_save)\n",
    "        self.model_save = {}\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ae814-92df-44e2-b719-d4a7b0163447",
   "metadata": {},
   "source": [
    "## Define Function to Select Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb2cc84-7c7a-47c3-bf94-b410b12222cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_data_select(data, drop_list,target,ohe_feats_drop=None,test_size=None):\n",
    "    data.drop(columns=drop_list,inplace=True,axis=1)\n",
    "    if ohe_feats_drop:\n",
    "        for feat in ohe_feats_drop:\n",
    "            data.drop(columns=data.filter(like=feat+'_').columns, inplace=True, axis=1)\n",
    "        \n",
    "    X = data\n",
    "    y = data.pop(target)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=test_size)\n",
    "\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105c682-8f28-4ae9-981e-cb78dd24cc30",
   "metadata": {},
   "source": [
    "## Define Function to Iterate Through Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc57c499-e5a6-474b-b3e7-27d31264006f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_iterator(data,X_valid,y_valid,params,model_dict,fname,dirname,target):\n",
    "    for i, (k,v) in enumerate(model_dict.items()):\n",
    "        #Print iteration number\n",
    "        logger.info(f\"Training model {i+1}/{len(model_dict)}\")\n",
    "        #Initialize model saver class\n",
    "        if i == 0:\n",
    "            logging.info('Initializing ModelSaver class')\n",
    "        \n",
    "            model_saver = ModelSaver(\n",
    "            v['algorithm'],\n",
    "            X_valid,\n",
    "            y_valid,\n",
    "            output_dir='/Users/richardmiller/Downloads/',\n",
    "            iteration_start=i,\n",
    "            params=params,\n",
    "        )\n",
    "            algorithm_ = v['algorithm']\n",
    "            \n",
    "        #Check if model changed between iterations\n",
    "        if v['algorithm'] != algorithm_:\n",
    "            model_saver.update_state(v['algorithm'],i)\n",
    "\n",
    "            \n",
    "        logging.info('Training Model.')\n",
    "\n",
    "        if v['algorithm'] == 'RandomForestClassifier':\n",
    "            #Split data into train and test sets\n",
    "            X_train, X_test, y_train, y_test = model_data_select(\n",
    "                data=deepcopy(data),\n",
    "                drop_list=v['drop_list'],\n",
    "                ohe_feats_drop=v['ohe_feats_drop'],\n",
    "                target=target\n",
    "            )\n",
    "    \n",
    "            #Fit model\n",
    "            rf_model = RandomForestClassifier()\n",
    "            rf_model.fit(X_train, y_train)\n",
    "    \n",
    "            #Make predictions and evaluate with report metric\n",
    "            preds = rf_model.predict(X_test)\n",
    "            report = classification_report(y_test,preds,output_dict=True)\n",
    "            logging.info('Model trained.')\n",
    "\n",
    "        elif v['algorithm'] == 'XGBClassifier':\n",
    "            xgb_model = XGBClassifier()\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "\n",
    "            preds = xgb_model.predict(X_test)\n",
    "            report = classification_report(y_test,preds)\n",
    "            \n",
    "        logging.info('Saving state.')\n",
    "\n",
    "        #Append current model data to all other data.\n",
    "        model_saver.record_state(\n",
    "        model=rf_model,\n",
    "        X_test=X_test,\n",
    "        X_train=X_train,\n",
    "        y_test=y_test,\n",
    "        y_train=y_train,\n",
    "        model_scores=report,\n",
    "        model_preds=preds,\n",
    "        drop_list=v['drop_list'],\n",
    "        model_notes=v['model_notes'],\n",
    "    )\n",
    "        logging.info('State saved successfully')\n",
    "\n",
    "        #Set the test variable\n",
    "        algorithm_ = v['algorithm']\n",
    "\n",
    "        if i == len(model_dict)-1:\n",
    "            model_saver.save_state(output_fname=fname, output_dir=dirname)\n",
    "\n",
    "            logger.info('--------------------------------------------------')\n",
    "            logger.info('-ALL MODELS TRAINED AND SAVED TO DISK SUCCESSFULLY-')\n",
    "            logger.info('--------------------------------------------------')\n",
    "    return model_saver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69941cc0-c9e5-4900-b399-944f88641886",
   "metadata": {},
   "source": [
    "## Load Raw Data Set from disk, split off validation set, pass data to pipeline for encoding/transforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9a799-40bb-4550-84dd-a2b1c1eca51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "fpath = '/Users/richardmiller/Downloads/thyroid_cancer_risk_data.csv'\n",
    "X_raw = pd.read_csv(fpath)\n",
    "y_raw = X_raw.pop('Diagnosis')\n",
    "\n",
    "#Split off validation set\n",
    "X, X_valid, y, y_valid = train_test_split(X_raw,y_raw,test_size=0.2,stratify=y_raw)\n",
    "\n",
    "#Load and encode/transform data\n",
    "data = pd.concat([X,y],axis=1)\n",
    "pipeline = EncodingPipeLine(raw_data=deepcopy(data),logger=logger,ratios='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db4b378-e763-41f7-ad62-f78654a87ebf",
   "metadata": {},
   "source": [
    "## Save Encoded/Transformed Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65bab1-193f-44d1-8dde-86d8c3d7793a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "data_save = {\n",
    "    'X_valid':X_valid,\n",
    "    'y_valid':y_valid,\n",
    "    'data':pipeline.data,\n",
    "}\n",
    "\n",
    "with open(\"resampled_data.pkl\", \"wb\") as f:\n",
    "    joblib.dump(data_save, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23902b17-e58c-44ec-b246-71720c2c74ba",
   "metadata": {},
   "source": [
    "## Load Encoded/Transformed Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "764e5d5b-286f-4408-b4f0-cbaf4a8e68e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "with open(\"resampled_data.pkl\",\"rb\") as f:\n",
    "    encoded_data = joblib.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7d3546-df0d-471e-9d4c-3a02c16ef5d0",
   "metadata": {},
   "source": [
    "## RandomForestModel:\n",
    "\n",
    "1. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; No Ethnicity, No Country, No Gender; Transforms: None\n",
    "2. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; Yes Ethnicity, No Country, No Gender; Transforms: None\n",
    "3. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; No Ethnicity, Yes Country, No Gender; Transforms: None\n",
    "4. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; No Ethnicity, No Country, Yes Gender; Transforms: None\n",
    "5. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; Yes Ethnicity, Yes Country, No Gender; Transforms: None\n",
    "6. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; Yes Ethnicity, No Country, Yes Gender; Transforms: None\n",
    "7. Ratios: Nodule_Size:T4_Level, TSH_Level:T3_Level; No Ethnicity, Yes Country, Yes Gender; Transforms: None\n",
    "8. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; No Ethnicity, No Country, No Gender; Transforms: None\n",
    "9. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; Yes Ethnicity, No Country, No Gender; Transforms: None\n",
    "10. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; No Ethnicity, Yes Country, No Gender; Transforms: None\n",
    "11. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; No Ethnicity, No Country, Yes Gender; Transforms: None\n",
    "12. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; Yes Ethnicity, Yes Country, No Gender; Transforms: None\n",
    "13. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; Yes Ethnicity, No Country, Yes Gender; Transforms: None\n",
    "14. Ratios: Nodule_Size:T3_Level, TSH_Level:T4_Level; No Ethnicity, Yes Country, Yes Gender; Transforms: None\n",
    "15. Ratios: None; No Ethnicity, No Country, No Gender; Transforms:sqrt\n",
    "16. Ratios: None; Yes Ethnicity, No Country, No Gender; Transforms:sqrt\n",
    "17. Ratios: None; No Ethnicity, Yes Country, No Gender; Transforms:sqrt\n",
    "18. Ratios: None; No Ethnicity, No Country, Yes Gender; Transforms:sqrt\n",
    "19. Ratios: None; Yes Ethnicity, Yes Country, No Gender; Transforms:sqrt\n",
    "20. Ratios: None; Yes Ethnicity, No Country, Yes Gender; Transforms:sqrt\n",
    "21. Ratios: None; No Ethnicity, Yes Country, Yes Gender; Transforms:sqrt\n",
    "22. Ratios: None; Yes Ethnicity, Yes Country, Yes Gender; Transforms:sqrt\n",
    "23. Ratios: None; No Ethnicity, No Country, No Gender; Transforms:log\n",
    "24. Ratios: None; Yes Ethnicity, No Country, No Gender; Transforms:log\n",
    "25. Ratios: None; No Ethnicity, Yes Country, No Gender; Transforms:log\n",
    "26. Ratios: None; No Ethnicity, No Country, Yes Gender; Transforms:log\n",
    "27. Ratios: None; Yes Ethnicity, Yes Country, No Gender; Transforms:log\n",
    "28. Ratios: None; Yes Ethnicity, No Country, Yes Gender; Transforms:log\n",
    "29. Ratios: None; No Ethnicity, Yes Country, Yes Gender; Transforms:log\n",
    "30. Ratios: None; Yes Ethnicity, Yes Country, Yes Gender; Transforms:log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c88c55c-56d2-496e-90fb-d37973bd9ec9",
   "metadata": {},
   "source": [
    "## Define dictionary with model info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59bb2826-bee5-47c0-9fdb-d5f0e3e86c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_models = {\n",
    "    #RandomForestClassifiers\n",
    "    'model_1':{\n",
    "        'ohe_feats_drop':['Country','Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No',\n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    'model_2':{\n",
    "        'ohe_feats_drop':['Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios':'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'Yes', \n",
    "            'Country':'No',\n",
    "            'Gender':'No',\n",
    "            'Transforms': None\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_3':{\n",
    "        'ohe_feats_drop':['Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes',\n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_4':{\n",
    "        'ohe_feats_drop':['Country','Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_5':{\n",
    "        'ohe_feats_drop':['log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_6':{\n",
    "        'ohe_feats_drop':['Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_7':{\n",
    "        'ohe_feats_drop':['Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T4_Level, TSH_Level:T3_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_8':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_9':{\n",
    "        'ohe_feats_drop':['Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_10':{\n",
    "        'ohe_feats_drop':['Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_11':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_12':{\n",
    "        'ohe_feats_drop':['log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    'model_13':{\n",
    "        'ohe_feats_drop':['Country','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_14':{\n",
    "        'ohe_feats_drop':['Ethnicity','log','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':None,\n",
    "        'model_notes':{\n",
    "            'Ratios': 'Nodule_Size:T3_Level, TSH_Level:T4_Level',\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': None,\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_15':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    'model_16':{\n",
    "        'ohe_feats_drop':['Country','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_17':{\n",
    "        'ohe_feats_drop':['Ethnicity','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_18':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_19':{\n",
    "        'ohe_feats_drop':['log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_20':{\n",
    "        'ohe_feats_drop':['Country','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_21':{\n",
    "        'ohe_feats_drop':['Ethnicity','log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_22':{\n",
    "        'ohe_feats_drop':['log'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'sqrt',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'sqrt',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_23':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    'model_24':{\n",
    "        'ohe_feats_drop':['Country','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_25':{\n",
    "        'ohe_feats_drop':['Ethnicity','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_26':{\n",
    "        'ohe_feats_drop':['Ethnicity','Country','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_27':{\n",
    "        'ohe_feats_drop':['sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID','Gender',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'No',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_28':{\n",
    "        'ohe_feats_drop':['Country','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'No', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_29':{\n",
    "        'ohe_feats_drop':['Ethnicity','sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'No',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "    \n",
    "    'model_30':{\n",
    "        'ohe_feats_drop':['sqrt'],\n",
    "        'algorithm':'RandomForestClassifier',\n",
    "        'drop_list':['Nodule_Size:T4_Level','TSH_Level:T3_Level','Nodule_Size:T3_Level','TSH_Level:T4_Level','T4_Level','T3_Level','Nodule_Size','TSH_Level','Patient_ID',],\n",
    "        'continuous_transforms':'log',\n",
    "        'model_notes':{\n",
    "            'Ratios': None,\n",
    "            'Ethnicity':'Yes',\n",
    "            'Country':'Yes', \n",
    "            'Gender':'Yes',\n",
    "            'Transforms': 'log',\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af48630-1497-434d-bb80-a53346dec760",
   "metadata": {},
   "source": [
    "## Code to check model dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf484625-b47a-4980-8b15-ffd78a467a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(k,v) in enumerate(models.items()):\n",
    "    not_included = []\n",
    "    data_ = deepcopy(encoded_data['data'])\n",
    "    \n",
    "    not_included = deepcopy(models['model_'+str(i+1)]['drop_list'])\n",
    "    ohe_feats = v['ohe_feats_drop']\n",
    "    if ohe_feats != None:\n",
    "        not_included.extend(models['model_'+str(i+1)]['ohe_feats_drop'])\n",
    "    X, _,_,_ = model_data_select(data=data_,drop_list=v['drop_list'],target='Diagnosis',ohe_feats_drop=v['ohe_feats_drop'],)\n",
    "    for col in X.columns:\n",
    "        if col in not_included:\n",
    "            print('model_'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c33a2c94-2368-4114-8f40-089754bed7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "            'feat_categories':{\n",
    "                'numerical_continuous':['TSH_Level','T3_Level','T4_Level','Nodule_Size',],\n",
    "                'ordinal':['Age'],\n",
    "                'binary':['Gender','Family_History','Radiation_Exposure','Iodine_Deficiency',\n",
    "                    'Smoking','Obesity','Diabetes','Diagnosis',],\n",
    "                'categorical_nominal':['Country','Ethnicity',],\n",
    "                'categorical_ordinal':['Thyroid_Cancer_Risk',],\n",
    "            },\n",
    "            'encoding_utils':{\n",
    "                'binary':{'Yes':1.0,'No':0.0,'Male':1.0,'Female':0.0,'Benign':0.0,'Malignant':1.0},\n",
    "                'categorical_ordinal':{'Low':0.0,'Medium':1.0,'High':2.0},\n",
    "            },\n",
    "            'train_test':{\n",
    "                'test_size':0.2,\n",
    "            },\n",
    "            'feat_ratio_names':{\n",
    "                'ratio_1':['TSH_Level','T3_Level'],\n",
    "                'ratio_2':['Nodule_Size','T4_Level'],\n",
    "                'ratio_3':['TSH_Level','T4_Level'],\n",
    "                'ratio_4':['Nodule_Size','T3_Level']\n",
    "            },\n",
    "            'resample':'SMOTETomek',\n",
    "            'target_name':'Diagnosis',\n",
    "            \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a73b28-a649-40df-bd97-3dcfc94be8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing = model_iterator(\n",
    "    data=deepcopy(encoded_data['data']),\n",
    "    X_valid=encoded_data['X_valid'],y_valid=encoded_data['y_valid'],\n",
    "    params=params,\n",
    "    model_dict=rf_models,\n",
    "    fname='rf_model_out.dill',dirname='/Users/richardmiller/Downloads/',\n",
    "    target='Diagnosis',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c877bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"/Users/richardmiller/Downloads/rf_model_out.dill\", \"wb\") as f:\n",
    "    dill.dump(thing.model_out, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f40423b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/richardmiller/Downloads/rf_model_out.dill\", \"rb\") as f:\n",
    "    models = dill.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1769732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = {}\n",
    "for i,model in enumerate(models['RandomForestClassifier'].keys()):\n",
    "    if models['RandomForestClassifier'][model]['model_scores']['0.0']['precision'] > 0.845:\n",
    "        selected_models[model] = {\n",
    "            'benign_precision':models['RandomForestClassifier'][model]['model_scores']['0.0']['precision'],\n",
    "            'malignant_precision':models['RandomForestClassifier'][model]['model_scores']['1.0']['precision'],\n",
    "            'model_notes':models['RandomForestClassifier'][model]['model_notes'],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "af380e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier_1\n",
      "Benign Precision: 0.8471464167062174\n",
      "Malignant Precision: 0.9379772769603278\n",
      "RandomForestClassifier_2\n",
      "Benign Precision: 0.847591128483018\n",
      "Malignant Precision: 0.9363100126931979\n",
      "RandomForestClassifier_4\n",
      "Benign Precision: 0.8481102712316585\n",
      "Malignant Precision: 0.933860263962419\n",
      "RandomForestClassifier_5\n",
      "Benign Precision: 0.8470367278797997\n",
      "Malignant Precision: 0.9359937807722207\n",
      "RandomForestClassifier_6\n",
      "Benign Precision: 0.8455660687102647\n",
      "Malignant Precision: 0.9365343387299475\n",
      "RandomForestClassifier_8\n",
      "Benign Precision: 0.8454446375445521\n",
      "Malignant Precision: 0.9387026458208058\n",
      "RandomForestClassifier_10\n",
      "Benign Precision: 0.8464939428773544\n",
      "Malignant Precision: 0.9344348479158844\n",
      "RandomForestClassifier_11\n",
      "Benign Precision: 0.8502006241640659\n",
      "Malignant Precision: 0.9341929250891795\n",
      "RandomForestClassifier_13\n",
      "Benign Precision: 0.847419373997743\n",
      "Malignant Precision: 0.9346055127775917\n",
      "RandomForestClassifier_16\n",
      "Benign Precision: 0.8482797518330514\n",
      "Malignant Precision: 0.9359880908075922\n",
      "RandomForestClassifier_17\n",
      "Benign Precision: 0.8465641390345808\n",
      "Malignant Precision: 0.9333457665050354\n",
      "RandomForestClassifier_18\n",
      "Benign Precision: 0.8470542681837135\n",
      "Malignant Precision: 0.9356261349738725\n",
      "RandomForestClassifier_19\n",
      "Benign Precision: 0.8485443829255224\n",
      "Malignant Precision: 0.9360976152505285\n",
      "RandomForestClassifier_20\n",
      "Benign Precision: 0.8478016450677555\n",
      "Malignant Precision: 0.9362083784894801\n",
      "RandomForestClassifier_21\n",
      "Benign Precision: 0.8474636818290069\n",
      "Malignant Precision: 0.9360281846838494\n",
      "RandomForestClassifier_24\n",
      "Benign Precision: 0.8468628671349396\n",
      "Malignant Precision: 0.9381339498806682\n",
      "RandomForestClassifier_26\n",
      "Benign Precision: 0.8498342018000947\n",
      "Malignant Precision: 0.9334229491057092\n",
      "RandomForestClassifier_27\n",
      "Benign Precision: 0.8470073774393146\n",
      "Malignant Precision: 0.9347091793177684\n",
      "RandomForestClassifier_28\n",
      "Benign Precision: 0.8464314235854359\n",
      "Malignant Precision: 0.9327052489905787\n",
      "RandomForestClassifier_29\n",
      "Benign Precision: 0.8488807077964492\n",
      "Malignant Precision: 0.9355534883720931\n"
     ]
    }
   ],
   "source": [
    "model_keys = list(selected_models.keys())\n",
    "for k,v in selected_models.items():\n",
    "    print(k)\n",
    "    print(f\"Benign Precision: {v['benign_precision']}\")\n",
    "    print(f\"Malignant Precision: {v['malignant_precision']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e7c3a9",
   "metadata": {},
   "source": [
    "The most promising model looks to be the one that includes Ethnicity, Country, Gender, and performs a log transform on the numeric continuous features. I will use those features to do a grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8026e1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 216 candidates, totalling 648 fits\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   4.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  18.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  16.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  16.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   4.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  22.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  20.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  29.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  27.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  21.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   9.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  19.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  33.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  34.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  20.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  26.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  24.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  34.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   8.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  32.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  34.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   7.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  37.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  18.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  49.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   7.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   8.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  56.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  12.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   3.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  17.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   8.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  14.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  21.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.0s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  28.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  27.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  21.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  36.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   8.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  39.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=  11.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  20.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  23.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  17.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   9.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  32.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  17.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  32.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  31.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  37.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  49.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   9.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  19.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  56.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  25.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  23.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  22.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   4.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  15.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   8.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  15.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  16.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   4.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  11.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  21.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  22.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  21.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  26.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  29.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  20.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  34.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  40.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  35.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  21.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  20.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  24.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  34.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   8.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  31.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  18.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  15.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  31.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  43.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  13.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  41.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  37.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=  20.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  21.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  24.1s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  23.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  11.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  23.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  15.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  18.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  15.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  22.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  21.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  14.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  29.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  22.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  39.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  36.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   8.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  41.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  37.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  11.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  20.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  21.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  13.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   8.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  16.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  34.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  31.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   9.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  31.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   9.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  25.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  24.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  38.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  51.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  21.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   5.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  12.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  21.7s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.5s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  22.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  17.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=   9.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   4.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  15.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   3.8s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   3.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  26.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  21.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  10.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  21.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  20.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  29.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   6.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  13.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  26.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   8.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  39.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   9.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  18.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   8.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   9.3s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  20.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  34.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  20.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  26.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  23.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  23.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   7.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  30.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  34.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   7.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  15.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  37.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  16.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  23.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  36.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   7.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  19.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  52.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  23.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  22.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   4.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  18.4s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   4.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  16.2s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  17.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  21.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  20.8s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  25.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  15.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  26.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  13.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  29.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   6.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  38.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  35.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  34.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   9.0s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  21.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  37.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  10.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  21.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  13.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  25.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  23.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  17.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   9.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.0s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  15.1s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   7.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   9.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  15.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   7.7s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  31.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   9.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.9s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  49.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   9.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  19.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   8.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=  20.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  30.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.2s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  24.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  11.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.8s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  22.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   4.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=   7.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   4.0s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  18.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   8.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  16.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=   7.9s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   4.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  15.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   8.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  11.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  11.0s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  22.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  27.7s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.8s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   7.2s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  26.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  39.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   9.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  34.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   9.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  43.4s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  11.2s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  10.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  10.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  26.0s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  24.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   5.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  11.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  17.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  30.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  31.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   8.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  18.5s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   8.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  31.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  37.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   8.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=  24.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=  13.1s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  20.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  19.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  38.3s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=  20.4s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  31.2s\n"
     ]
    }
   ],
   "source": [
    "#Get encoded train and test data\n",
    "drop_list = [\n",
    "    'Nodule_Size:T4_Level',\n",
    "    'TSH_Level:T3_Level',\n",
    "    'Nodule_Size:T3_Level',\n",
    "    'TSH_Level:T4_Level',\n",
    "    'T4_Level',\n",
    "    'T3_Level',\n",
    "    'Nodule_Size',\n",
    "    'TSH_Level',\n",
    "    'Patient_ID',\n",
    "]\n",
    "data = pd.DataFrame(encoded_data['data'])\n",
    "[X_test, X_train, y_test, y_train] = model_data_select(\n",
    "    data=data,\n",
    "    target='Diagnosis',\n",
    "    drop_list=drop_list,\n",
    "    ohe_feats_drop=['sqrt'],\n",
    "    test_size=0.2\n",
    ")\n",
    "\n",
    "#Define grid params\n",
    "grid_params = {\n",
    "    'n_estimators':[50, 100, 200,],\n",
    "    'max_depth':[None, 10, 20, 30,],\n",
    "    'min_samples_split':[2,5,10,],\n",
    "    'min_samples_leaf':[1,2,4,],\n",
    "    'bootstrap':[True,False,],\n",
    "}\n",
    "\n",
    "#Define model and grid search\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=random_forest,\n",
    "    param_grid = grid_params,\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='accuracy',\n",
    ")\n",
    "\n",
    "gs = grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f52ef67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_gridsearch_accuracy.pkl']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   6.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.6s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  24.4s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  12.0s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   5.9s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  23.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   5.3s\n",
      "[CV] END bootstrap=True, max_depth=None, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  23.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   4.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=   7.6s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=1, min_samples_split=10, n_estimators=100; total time=   9.5s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  17.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   4.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=   7.7s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=   8.3s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  16.1s\n",
      "[CV] END bootstrap=True, max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=   7.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  13.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   6.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  22.7s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   5.4s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.9s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  22.3s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   5.1s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  10.6s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  10.2s\n",
      "[CV] END bootstrap=True, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  21.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  12.3s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  30.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  26.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   6.5s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  12.9s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  16.4s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  22.6s\n",
      "[CV] END bootstrap=True, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  10.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.2s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=50; total time=   8.9s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  38.7s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=50; total time=   9.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  18.5s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.1s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=2, n_estimators=200; total time=  42.8s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=50; total time=   9.6s\n",
      "[CV] END bootstrap=False, max_depth=None, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  16.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   5.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  24.9s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  20.8s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  10.1s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   5.5s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=  24.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=50; total time=   6.7s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=2, n_estimators=100; total time=  12.6s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   7.3s\n",
      "[CV] END bootstrap=False, max_depth=10, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  21.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.8s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=200; total time=  33.2s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=50; total time=   9.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=1, min_samples_split=10, n_estimators=200; total time=  31.9s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=50; total time=   7.4s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=5, n_estimators=100; total time=  16.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=100; total time=  15.3s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  35.6s\n",
      "[CV] END bootstrap=False, max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=200; total time=  31.0s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=50; total time=   9.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  18.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=100; total time=  18.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time=  48.2s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=2, n_estimators=200; total time=  40.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=50; total time=   8.6s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=  33.5s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=50; total time=   8.8s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=5, n_estimators=100; total time=  22.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=100; total time=  33.7s\n",
      "[CV] END bootstrap=False, max_depth=30, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=  21.4s\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(gs,'random_forest_gridsearch_accuracy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8d7ed3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102673976224086\n",
      "{'bootstrap': False, 'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_)\n",
    "print(gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b4e64273",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_acc = joblib.load('random_forest_gridsearch_accuracy.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
